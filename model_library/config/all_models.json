{
    "kimi/kimi-k2-thinking": {
        "company": "Kimi",
        "label": "Kimi K2 Thinking",
        "description": null,
        "release_date": "2025-11-06",
        "open_source": true,
        "documentation_url": "https://platform.moonshot.ai/docs",
        "properties": {
            "context_window": 128000,
            "max_token_output": 128000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.6,
            "output": 2.5
        },
        "alternative_keys": [
            {
                "fireworks/kimi-k2-thinking": {
                    "costs_per_million_token": {
                        "input": 0.5,
                        "output": 0.5,
                        "cache": {
                            "read_discount": 1
                        }
                    }
                }
            }
        ],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 1.0
        },
        "provider_name": "kimi",
        "provider_endpoint": "kimi-k2-thinking",
        "full_key": "kimi/kimi-k2-thinking",
        "slug": "kimi_kimi-k2-thinking"
    },
    "inception/mercury": {
        "company": "Inception",
        "label": "Mercury",
        "description": null,
        "release_date": "2025-11-06",
        "open_source": false,
        "documentation_url": "https://docs.inceptionlabs.ai/get-started/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.25,
            "output": 1.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 16400
        },
        "provider_name": "inception",
        "provider_endpoint": "mercury",
        "full_key": "inception/mercury",
        "slug": "inception_mercury"
    },
    "fireworks/kimi-k2-thinking": {
        "company": "Kimi",
        "label": "Kimi K2 Thinking",
        "description": null,
        "release_date": "2025-11-06",
        "open_source": true,
        "documentation_url": "https://platform.moonshot.ai/docs",
        "properties": {
            "context_window": 128000,
            "max_token_output": 128000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 0.5,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 1.0
        },
        "provider_name": "fireworks",
        "provider_endpoint": "kimi-k2-thinking",
        "full_key": "fireworks/kimi-k2-thinking",
        "slug": "fireworks_kimi-k2-thinking"
    },
    "fireworks/minimax-m2": {
        "company": "MiniMax AI",
        "label": "MiniMax-M2",
        "description": "MiniMax-M2 is a cost-efficient open-source model optimized for agentic applications and coding in particular.",
        "release_date": "2025-10-26",
        "open_source": true,
        "documentation_url": "https://platform.minimax.io/docs",
        "properties": {
            "context_window": 204800,
            "max_token_output": 131000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 1.2,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "top_p": 0.95
        },
        "provider_name": "fireworks",
        "provider_endpoint": "minimax-m2",
        "full_key": "fireworks/minimax-m2",
        "slug": "fireworks_minimax-m2"
    },
    "anthropic/claude-haiku-4-5-20251001-thinking": {
        "company": "Anthropic",
        "label": "Claude Haiku 4.5 (Thinking)",
        "description": null,
        "release_date": "2025-10-15",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 64000,
            "training_cutoff": "2025-07",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.0,
            "output": 5.0,
            "cache": {
                "read": 0.1,
                "write": 1.25,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-haiku-4-5-20251001",
        "full_key": "anthropic/claude-haiku-4-5-20251001-thinking",
        "slug": "anthropic_claude-haiku-4-5-20251001-thinking"
    },
    "anthropic/claude-haiku-4-5-20251001": {
        "company": "Anthropic",
        "label": "Claude Haiku 4.5 (Nonthinking)",
        "description": null,
        "release_date": "2025-10-15",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 64000,
            "training_cutoff": "2025-07",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.0,
            "output": 5.0,
            "cache": {
                "read": 0.1,
                "write": 1.25,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "anthropic/claude-haiku-4-5-20251001-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-haiku-4-5-20251001",
        "full_key": "anthropic/claude-haiku-4-5-20251001",
        "slug": "anthropic_claude-haiku-4-5-20251001"
    },
    "zai/glm-4.6": {
        "company": "zAI",
        "label": "GLM 4.6",
        "description": "z.AI flagship model",
        "release_date": "2025-09-30",
        "open_source": true,
        "documentation_url": "https://docs.z.ai/",
        "properties": {
            "context_window": 200000,
            "max_token_output": 122880,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.6,
            "output": 2.2,
            "cache": {
                "read": 0.11,
                "read_discount": 1.0,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [
            "fireworks/glm-4p6"
        ],
        "default_parameters": {
            "temperature": 0.6,
            "top_p": 1.0
        },
        "provider_name": "zai",
        "provider_endpoint": "glm-4.6",
        "full_key": "zai/glm-4.6",
        "slug": "zai_glm-4.6"
    },
    "fireworks/glm-4p6": {
        "company": "zAI",
        "label": "GLM 4.6",
        "description": "z.AI flagship model",
        "release_date": "2025-09-30",
        "open_source": true,
        "documentation_url": "https://docs.z.ai/",
        "properties": {
            "context_window": 200000,
            "max_token_output": 122880,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.6,
            "output": 2.2,
            "cache": {
                "read": 0.11,
                "read_discount": 1.0,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.6,
            "top_p": 1.0
        },
        "provider_name": "fireworks",
        "provider_endpoint": "glm-4p6",
        "full_key": "fireworks/glm-4p6",
        "slug": "fireworks_glm-4p6"
    },
    "deepseek/deepseek-reasoner": {
        "company": "DeepSeek",
        "label": "DeepSeek V3.2-Exp (Thinking)",
        "description": "DeepSeek V3.2-Exp model with thinking mode for complex reasoning",
        "release_date": "2025-09-29",
        "open_source": true,
        "documentation_url": "https://api-docs.deepseek.com/",
        "properties": {
            "context_window": 128000,
            "max_token_output": 64000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.28,
            "output": 0.42
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "deepseek",
        "provider_endpoint": "deepseek-reasoner",
        "full_key": "deepseek/deepseek-reasoner",
        "slug": "deepseek_deepseek-reasoner"
    },
    "deepseek/deepseek-chat": {
        "company": "DeepSeek",
        "label": "DeepSeek V3.2-Exp (Nonthinking)",
        "description": "DeepSeek V3.2-Exp model for general conversation",
        "release_date": "2025-09-29",
        "open_source": true,
        "documentation_url": "https://api-docs.deepseek.com/",
        "properties": {
            "context_window": 128000,
            "max_token_output": 8000,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.28,
            "output": 0.42
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "deepseek",
        "provider_endpoint": "deepseek-chat",
        "full_key": "deepseek/deepseek-chat",
        "slug": "deepseek_deepseek-chat"
    },
    "anthropic/claude-sonnet-4-5-20250929-thinking": {
        "company": "Anthropic",
        "label": "Claude Sonnet 4.5 (Thinking)",
        "description": "Anthropic's latest flagship model",
        "release_date": "2025-09-29",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 1000000,
            "max_token_output": 64000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.3,
                "write": 3.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            },
            "context": {
                "threshold": 200000.0,
                "input": 6.0,
                "output": 22.5,
                "cache": {
                    "read": 0.6,
                    "write": 7.5,
                    "write_markup": 1.0
                }
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-sonnet-4-5-20250929",
        "full_key": "anthropic/claude-sonnet-4-5-20250929-thinking",
        "slug": "anthropic_claude-sonnet-4-5-20250929-thinking"
    },
    "anthropic/claude-sonnet-4-5-20250929": {
        "company": "Anthropic",
        "label": "Claude Sonnet 4.5 (Nonthinking)",
        "description": "Anthropic's latest flagship model",
        "release_date": "2025-09-29",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 1000000,
            "max_token_output": 64000,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.3,
                "write": 3.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            },
            "context": {
                "threshold": 200000.0,
                "input": 6.0,
                "output": 22.5,
                "cache": {
                    "read": 0.6,
                    "write": 7.5,
                    "write_markup": 1.0
                }
            }
        },
        "alternative_keys": [
            {
                "anthropic/claude-sonnet-4-5-20250929-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-sonnet-4-5-20250929",
        "full_key": "anthropic/claude-sonnet-4-5-20250929",
        "slug": "anthropic_claude-sonnet-4-5-20250929"
    },
    "google/gemini-2.5-flash-preview-09-2025-thinking": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Preview (9/25) (Thinking)",
        "description": "Gemini 2.5 Flash is the best price-performance model suitable for large scale processing with support for multiple modalities.",
        "release_date": "2025-09-25",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65535,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 2.5,
            "cache": {
                "read": 0.03,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-preview-09-2025",
        "full_key": "google/gemini-2.5-flash-preview-09-2025-thinking",
        "slug": "google_gemini-2.5-flash-preview-09-2025-thinking"
    },
    "google/gemini-2.5-flash-preview-09-2025": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Preview (9/25) (Nonthinking)",
        "description": "Gemini 2.5 Flash is the best price-performance model suitable for large scale processing with support for multiple modalities.",
        "release_date": "2025-09-25",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65535,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 2.5,
            "cache": {
                "read": 0.03,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "google/gemini-2.5-flash-preview-09-2025-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-preview-09-2025",
        "full_key": "google/gemini-2.5-flash-preview-09-2025",
        "slug": "google_gemini-2.5-flash-preview-09-2025"
    },
    "google/gemini-2.5-flash-lite-preview-09-2025-thinking": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Lite (9/25) (Thinking)",
        "description": "Gemini 2.5 Flash-Lite offers ultra-fast, cost-efficient processing at scale, with support for text, images, video, and audio input modalities and large context length.",
        "release_date": "2025-09-25",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65535,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.4,
            "cache": {
                "read": 0.01,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-lite-preview-09-2025",
        "full_key": "google/gemini-2.5-flash-lite-preview-09-2025-thinking",
        "slug": "google_gemini-2.5-flash-lite-preview-09-2025-thinking"
    },
    "google/gemini-2.5-flash-lite-preview-09-2025": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Lite (9/25) (Nonthinking)",
        "description": "Gemini 2.5 Flash-Lite offers ultra-fast, cost-efficient processing at scale, with support for text, images, video, and audio input modalities and large context length.",
        "release_date": "2025-09-25",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65535,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.4,
            "cache": {
                "read": 0.01,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "google/gemini-2.5-flash-lite-preview-09-2025-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-lite-preview-09-2025",
        "full_key": "google/gemini-2.5-flash-lite-preview-09-2025",
        "slug": "google_gemini-2.5-flash-lite-preview-09-2025"
    },
    "openai/gpt-5-codex": {
        "company": "OpenAI",
        "label": "GPT 5 Codex",
        "description": "GPT-5-Codex is a version of GPT-5 optimized for agentic coding tasks.",
        "release_date": "2025-09-23",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-5-codex",
        "properties": {
            "context_window": 400000,
            "max_token_output": 128000,
            "training_cutoff": "2024-09",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 10.0,
            "cache": {
                "read": 0.125,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-5-codex",
        "full_key": "openai/gpt-5-codex",
        "slug": "openai_gpt-5-codex"
    },
    "alibaba/qwen3-vl-plus-2025-09-23": {
        "company": "Alibaba",
        "label": "Qwen 3 VL Plus",
        "description": "Qwen 3 VL Plus (2025-09-23)",
        "release_date": "2025-09-23",
        "open_source": true,
        "properties": {
            "context_window": 262144,
            "max_token_output": 32768,
            "training_cutoff": "",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 1.6
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "alibaba",
        "provider_endpoint": "qwen3-vl-plus-2025-09-23",
        "full_key": "alibaba/qwen3-vl-plus-2025-09-23",
        "slug": "alibaba_qwen3-vl-plus-2025-09-23"
    },
    "alibaba/qwen3-max-2025-09-23": {
        "company": "Alibaba",
        "label": "Qwen 3 Max 2025-09-23",
        "description": "Largest and most recent Qwen Model",
        "release_date": "2025-09-23",
        "open_source": false,
        "properties": {
            "context_window": 262144,
            "max_token_output": 65536,
            "training_cutoff": "",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 6.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "alibaba",
        "provider_endpoint": "qwen3-max-2025-09-23",
        "full_key": "alibaba/qwen3-max-2025-09-23",
        "slug": "alibaba_qwen3-max-2025-09-23"
    },
    "alibaba/qwen3-max": {
        "company": "Alibaba",
        "label": "Qwen 3 Max",
        "description": "Largest and most recent Qwen Model",
        "release_date": "2025-09-23",
        "open_source": false,
        "properties": {
            "context_window": 262144,
            "max_token_output": 65536,
            "training_cutoff": "",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 6.0,
            "cache": {
                "read_discount": 0.8,
                "write_markup": 1.0
            },
            "context": {
                "threshold": 32000.0,
                "input": 2.4,
                "output": 12.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "alibaba",
        "provider_endpoint": "qwen3-max",
        "full_key": "alibaba/qwen3-max",
        "slug": "alibaba_qwen3-max"
    },
    "grok/grok-4-fast-reasoning-latest": {
        "company": "xAI",
        "label": "Grok 4 Fast (Reasoning)",
        "description": "Latest advancement in cost-efficient reasoning models with unified architecture. Handles complex requests with deep chain-of-thought reasoning. Features 2M token context window and native tool use.",
        "release_date": "2025-09-19",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-4-fast-reasoning",
        "properties": {
            "context_window": 2000000,
            "max_token_output": 2000000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.5,
            "cache": {
                "read": 0.05,
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "context": {
                "threshold": 128000.0,
                "input": 0.4,
                "output": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-4-fast-reasoning",
        "full_key": "grok/grok-4-fast-reasoning-latest",
        "slug": "grok_grok-4-fast-reasoning-latest"
    },
    "grok/grok-4-fast-reasoning": {
        "company": "xAI",
        "label": "Grok 4 Fast (Reasoning)",
        "description": "Latest advancement in cost-efficient reasoning models with unified architecture. Handles complex requests with deep chain-of-thought reasoning. Features 2M token context window and native tool use.",
        "release_date": "2025-09-19",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-4-fast-reasoning",
        "properties": {
            "context_window": 2000000,
            "max_token_output": 2000000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.5,
            "cache": {
                "read": 0.05,
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "context": {
                "threshold": 128000.0,
                "input": 0.4,
                "output": 1.0
            }
        },
        "alternative_keys": [
            "grok/grok-4-fast",
            "grok/grok-4-fast-reasoning-latest"
        ],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-4-fast-reasoning",
        "full_key": "grok/grok-4-fast-reasoning",
        "slug": "grok_grok-4-fast-reasoning"
    },
    "grok/grok-4-fast-non-reasoning-latest": {
        "company": "xAI",
        "label": "Grok 4 Fast (Non-Reasoning)",
        "description": "Cost-efficient model focused on speed and efficiency for straightforward tasks like summarization or classification without deep logical processing. Unified architecture with reasoning variant, steered via system prompts.",
        "release_date": "2025-09-19",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-4-fast-non-reasoning",
        "properties": {
            "context_window": 2000000,
            "max_token_output": 2000000,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.5,
            "cache": {
                "read": 0.05,
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "context": {
                "threshold": 128000.0,
                "input": 0.4,
                "output": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 2000000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-4-fast-non-reasoning",
        "full_key": "grok/grok-4-fast-non-reasoning-latest",
        "slug": "grok_grok-4-fast-non-reasoning-latest"
    },
    "grok/grok-4-fast-non-reasoning": {
        "company": "xAI",
        "label": "Grok 4 Fast (Non-Reasoning)",
        "description": "Cost-efficient model focused on speed and efficiency for straightforward tasks like summarization or classification without deep logical processing. Unified architecture with reasoning variant, steered via system prompts.",
        "release_date": "2025-09-19",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-4-fast-non-reasoning",
        "properties": {
            "context_window": 2000000,
            "max_token_output": 2000000,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.5,
            "cache": {
                "read": 0.05,
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "context": {
                "threshold": 128000.0,
                "input": 0.4,
                "output": 1.0
            }
        },
        "alternative_keys": [
            "grok/grok-4-fast-non-reasoning-latest"
        ],
        "default_parameters": {
            "max_output_tokens": 2000000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-4-fast-non-reasoning",
        "full_key": "grok/grok-4-fast-non-reasoning",
        "slug": "grok_grok-4-fast-non-reasoning"
    },
    "grok/grok-4-fast": {
        "company": "xAI",
        "label": "Grok 4 Fast (Reasoning)",
        "description": "Latest advancement in cost-efficient reasoning models with unified architecture. Handles complex requests with deep chain-of-thought reasoning. Features 2M token context window and native tool use.",
        "release_date": "2025-09-19",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-4-fast-reasoning",
        "properties": {
            "context_window": 2000000,
            "max_token_output": 2000000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.5,
            "cache": {
                "read": 0.05,
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "context": {
                "threshold": 128000.0,
                "input": 0.4,
                "output": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-4-fast-reasoning",
        "full_key": "grok/grok-4-fast",
        "slug": "grok_grok-4-fast"
    },
    "mistralai/magistral-small-2509": {
        "company": "Mistral",
        "label": "Magistral Small 1.2 (09/2025)",
        "description": "Small reasoning model with vision support released in September 2025.",
        "release_date": "2025-09-18",
        "open_source": true,
        "documentation_url": "https://docs.mistral.ai/getting-started/models/models_overview/",
        "properties": {
            "context_window": 128000,
            "max_token_output": 128000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 1.5
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "mistralai",
        "provider_endpoint": "magistral-small-2509",
        "full_key": "mistralai/magistral-small-2509",
        "slug": "mistralai_magistral-small-2509"
    },
    "mistralai/magistral-medium-2509": {
        "company": "Mistral",
        "label": "Magistral Medium 1.2 (09/2025)",
        "description": "Reasoning model with vision support released in September 2025.",
        "release_date": "2025-09-18",
        "open_source": false,
        "documentation_url": "https://docs.mistral.ai/getting-started/models/models_overview/",
        "properties": {
            "context_window": 128000,
            "max_token_output": 128000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 5.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "mistralai",
        "provider_endpoint": "magistral-medium-2509",
        "full_key": "mistralai/magistral-medium-2509",
        "slug": "mistralai_magistral-medium-2509"
    },
    "alibaba/qwen3-max-preview": {
        "company": "Alibaba",
        "label": "Qwen 3 Max Preview",
        "description": "Preview of the largest and most recent Qwen Model",
        "release_date": "2025-09-05",
        "open_source": false,
        "properties": {
            "context_window": 262144,
            "max_token_output": 65536,
            "training_cutoff": "",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 6.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "alibaba",
        "provider_endpoint": "qwen3-max-preview",
        "full_key": "alibaba/qwen3-max-preview",
        "slug": "alibaba_qwen3-max-preview"
    },
    "fireworks/kimi-k2-instruct-0905": {
        "company": "Kimi",
        "label": "Kimi K2 Instruct 0905",
        "description": "Kimi K2 0905 is an updated version of Kimi K2, a state-of-the-art mixture-of-experts (MoE) language model with 32 billion activated parameters and 1 trillion total parameters. Kimi K2 0905 has improved coding abilities, a longer context window, and agentic tool use, and a longer (262K) context window.",
        "release_date": "2025-09-04",
        "open_source": true,
        "documentation_url": "https://www.kimi.com/",
        "properties": {
            "context_window": 256000,
            "max_token_output": 256000,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.6,
            "output": 2.5,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "fireworks",
        "provider_endpoint": "kimi-k2-instruct-0905",
        "full_key": "fireworks/kimi-k2-instruct-0905",
        "slug": "fireworks_kimi-k2-instruct-0905"
    },
    "grok/grok-code-fast-1-0825": {
        "company": "xAI",
        "label": "Grok Code Fast",
        "description": "A speedy and economical reasoning model that excels at agentic coding. Tailored specifically for code generation and debugging across multiple programming languages.",
        "release_date": "2025-08-25",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-code-fast-1",
        "properties": {
            "context_window": 256000,
            "max_token_output": 40000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 1.5,
            "cache": {
                "read": 0.02,
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 40000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-code-fast-1",
        "full_key": "grok/grok-code-fast-1-0825",
        "slug": "grok_grok-code-fast-1-0825"
    },
    "grok/grok-code-fast-1": {
        "company": "xAI",
        "label": "Grok Code Fast",
        "description": "A speedy and economical reasoning model that excels at agentic coding. Tailored specifically for code generation and debugging across multiple programming languages.",
        "release_date": "2025-08-25",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-code-fast-1",
        "properties": {
            "context_window": 256000,
            "max_token_output": 40000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 1.5,
            "cache": {
                "read": 0.02,
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [
            "grok/grok-code-fast",
            "grok/grok-code-fast-1-0825"
        ],
        "default_parameters": {
            "max_output_tokens": 40000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-code-fast-1",
        "full_key": "grok/grok-code-fast-1",
        "slug": "grok_grok-code-fast-1"
    },
    "grok/grok-code-fast": {
        "company": "xAI",
        "label": "Grok Code Fast",
        "description": "A speedy and economical reasoning model that excels at agentic coding. Tailored specifically for code generation and debugging across multiple programming languages.",
        "release_date": "2025-08-25",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-code-fast-1",
        "properties": {
            "context_window": 256000,
            "max_token_output": 40000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 1.5,
            "cache": {
                "read": 0.02,
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 40000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-code-fast-1",
        "full_key": "grok/grok-code-fast",
        "slug": "grok_grok-code-fast"
    },
    "fireworks/deepseek-v3p1": {
        "company": "DeepSeek",
        "label": "DeepSeek V3.1",
        "description": "",
        "release_date": "2025-08-21",
        "open_source": true,
        "documentation_url": "https://fireworks.ai/models",
        "properties": {
            "context_window": 163840,
            "max_token_output": 163840,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.56,
            "output": 1.68,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "fireworks",
        "provider_endpoint": "deepseek-v3p1",
        "full_key": "fireworks/deepseek-v3p1",
        "slug": "fireworks_deepseek-v3p1"
    },
    "openai/gpt-5-nano-2025-08-07": {
        "company": "OpenAI",
        "label": "GPT 5 Nano",
        "description": "GPT-5 nano is the fastest, most cost-efficient version of GPT-5, optimized for summarization and classification tasks.",
        "release_date": "2025-08-07",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-5-nano",
        "properties": {
            "context_window": 400000,
            "max_token_output": 128000,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.05,
            "output": 0.4,
            "cache": {
                "read": 0.005,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/gpt-5-nano-2025-08-07"
        ],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-5-nano-2025-08-07",
        "full_key": "openai/gpt-5-nano-2025-08-07",
        "slug": "openai_gpt-5-nano-2025-08-07"
    },
    "openai/gpt-5-mini-2025-08-07": {
        "company": "OpenAI",
        "label": "GPT 5 Mini",
        "description": "GPT-5 mini is a faster, more cost-efficient version of GPT-5 optimized for well-defined tasks.",
        "release_date": "2025-08-07",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-5-mini",
        "properties": {
            "context_window": 400000,
            "max_token_output": 128000,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.25,
            "output": 2.0,
            "cache": {
                "read": 0.025,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/gpt-5-mini-2025-08-07"
        ],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-5-mini-2025-08-07",
        "full_key": "openai/gpt-5-mini-2025-08-07",
        "slug": "openai_gpt-5-mini-2025-08-07"
    },
    "openai/gpt-5-2025-08-07": {
        "company": "OpenAI",
        "label": "GPT 5",
        "description": "GPT-5 is OpenAI's flagship model for coding, reasoning, and agentic tasks across domains.",
        "release_date": "2025-08-07",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-5",
        "properties": {
            "context_window": 400000,
            "max_token_output": 128000,
            "training_cutoff": "2025-07",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 10.0,
            "cache": {
                "read": 0.125,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/gpt-5-2025-08-07"
        ],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-5-2025-08-07",
        "full_key": "openai/gpt-5-2025-08-07",
        "slug": "openai_gpt-5-2025-08-07"
    },
    "azure/gpt-5-nano-2025-08-07": {
        "company": "OpenAI",
        "label": "GPT 5 Nano",
        "description": "GPT-5 nano is the fastest, most cost-efficient version of GPT-5, optimized for summarization and classification tasks.",
        "release_date": "2025-08-07",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-5-nano",
        "properties": {
            "context_window": 400000,
            "max_token_output": 128000,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.05,
            "output": 0.4,
            "cache": {
                "read": 0.005,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "gpt-5-nano-2025-08-07",
        "full_key": "azure/gpt-5-nano-2025-08-07",
        "slug": "azure_gpt-5-nano-2025-08-07"
    },
    "azure/gpt-5-mini-2025-08-07": {
        "company": "OpenAI",
        "label": "GPT 5 Mini",
        "description": "GPT-5 mini is a faster, more cost-efficient version of GPT-5 optimized for well-defined tasks.",
        "release_date": "2025-08-07",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-5-mini",
        "properties": {
            "context_window": 400000,
            "max_token_output": 128000,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.25,
            "output": 2.0,
            "cache": {
                "read": 0.025,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "gpt-5-mini-2025-08-07",
        "full_key": "azure/gpt-5-mini-2025-08-07",
        "slug": "azure_gpt-5-mini-2025-08-07"
    },
    "azure/gpt-5-2025-08-07": {
        "company": "OpenAI",
        "label": "GPT 5",
        "description": "GPT-5 is OpenAI's flagship model for coding, reasoning, and agentic tasks across domains.",
        "release_date": "2025-08-07",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-5",
        "properties": {
            "context_window": 400000,
            "max_token_output": 128000,
            "training_cutoff": "2025-07",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 10.0,
            "cache": {
                "read": 0.125,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "gpt-5-2025-08-07",
        "full_key": "azure/gpt-5-2025-08-07",
        "slug": "azure_gpt-5-2025-08-07"
    },
    "fireworks/gpt-oss-20b": {
        "company": "OpenAI",
        "label": "GPT OSS 20B",
        "description": "",
        "release_date": "2025-08-05",
        "open_source": true,
        "documentation_url": "https://fireworks.ai/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 32768,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.05,
            "output": 0.2,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "fireworks",
        "provider_endpoint": "gpt-oss-20b",
        "full_key": "fireworks/gpt-oss-20b",
        "slug": "fireworks_gpt-oss-20b"
    },
    "fireworks/gpt-oss-120b": {
        "company": "OpenAI",
        "label": "GPT OSS 120B",
        "description": "",
        "release_date": "2025-08-05",
        "open_source": true,
        "documentation_url": "https://fireworks.ai/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 32768,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "fireworks",
        "provider_endpoint": "gpt-oss-120b",
        "full_key": "fireworks/gpt-oss-120b",
        "slug": "fireworks_gpt-oss-120b"
    },
    "bedrock/claude-opus-4-1-20250805-v1-thinking": {
        "company": "Amazon",
        "label": "Claude Opus 4.1 (Thinking)",
        "description": null,
        "release_date": "2025-08-05",
        "open_source": false,
        "documentation_url": "https://docs.anthropic.com/en/docs/models/claude-3-5-sonnet",
        "properties": {
            "context_window": 200000,
            "max_token_output": 32000,
            "training_cutoff": "2025-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "bedrock",
        "provider_endpoint": "us.anthropic.claude-opus-4-1-20250805-v1:0-thinking",
        "full_key": "bedrock/claude-opus-4-1-20250805-v1-thinking",
        "slug": "bedrock_claude-opus-4-1-20250805-v1-thinking"
    },
    "bedrock/claude-opus-4-1-20250805-v1": {
        "company": "Amazon",
        "label": "Claude Opus 4.1 (Nonthinking)",
        "description": null,
        "release_date": "2025-08-05",
        "open_source": false,
        "documentation_url": "https://docs.anthropic.com/en/docs/models/claude-3-5-sonnet",
        "properties": {
            "context_window": 200000,
            "max_token_output": 32000,
            "training_cutoff": "2025-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "bedrock",
        "provider_endpoint": "us.anthropic.claude-opus-4-1-20250805-v1:0",
        "full_key": "bedrock/claude-opus-4-1-20250805-v1",
        "slug": "bedrock_claude-opus-4-1-20250805-v1"
    },
    "anthropic/claude-opus-4-1-20250805-thinking": {
        "company": "Anthropic",
        "label": "Claude Opus 4.1 (Thinking)",
        "description": "Advanced model for specialized complex tasks with superior reasoning and 200K context window.",
        "release_date": "2025-08-05",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 32000,
            "training_cutoff": "2025-03",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0,
            "cache": {
                "read": 1.5,
                "write": 18.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-opus-4-1-20250805",
        "full_key": "anthropic/claude-opus-4-1-20250805-thinking",
        "slug": "anthropic_claude-opus-4-1-20250805-thinking"
    },
    "anthropic/claude-opus-4-1-20250805": {
        "company": "Anthropic",
        "label": "Claude Opus 4.1 (Nonthinking)",
        "description": "Advanced model for specialized complex tasks with superior reasoning and 200K context window.",
        "release_date": "2025-08-05",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 32000,
            "training_cutoff": "2025-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0,
            "cache": {
                "read": 1.5,
                "write": 18.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "anthropic/claude-opus-4-1-20250805-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-opus-4-1-20250805",
        "full_key": "anthropic/claude-opus-4-1-20250805",
        "slug": "anthropic_claude-opus-4-1-20250805"
    },
    "zai/glm-4.5-air": {
        "company": "zAI",
        "label": "GLM 4.5 Air",
        "description": "z.AI lightweight model",
        "release_date": "2025-07-28",
        "open_source": true,
        "documentation_url": "https://docs.z.ai/",
        "properties": {
            "context_window": 128000,
            "max_token_output": 81920,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 1.1,
            "cache": {
                "read": 0.03,
                "read_discount": 1.0,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [
            "together/zai-org/GLM-4.5-Air-FP8"
        ],
        "default_parameters": {
            "temperature": 0.6,
            "top_p": 1.0
        },
        "provider_name": "zai",
        "provider_endpoint": "glm-4.5-air",
        "full_key": "zai/glm-4.5-air",
        "slug": "zai_glm-4.5-air"
    },
    "zai/glm-4.5": {
        "company": "zAI",
        "label": "GLM 4.5",
        "description": "z.AI old model",
        "release_date": "2025-07-28",
        "open_source": true,
        "documentation_url": "https://docs.z.ai/",
        "properties": {
            "context_window": 128000,
            "max_token_output": 81920,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.6,
            "output": 2.2,
            "cache": {
                "read": 0.11,
                "read_discount": 1.0,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [
            "fireworks/glm-4p5"
        ],
        "default_parameters": {
            "temperature": 0.6,
            "top_p": 1.0
        },
        "provider_name": "zai",
        "provider_endpoint": "glm-4.5",
        "full_key": "zai/glm-4.5",
        "slug": "zai_glm-4.5"
    },
    "together/zai-org/GLM-4.5-Air-FP8": {
        "company": "zAI",
        "label": "GLM 4.5 Air",
        "description": "z.AI lightweight model",
        "release_date": "2025-07-28",
        "open_source": true,
        "documentation_url": "https://docs.z.ai/",
        "properties": {
            "context_window": 128000,
            "max_token_output": 81920,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 1.1,
            "cache": {
                "read": 0.03,
                "read_discount": 1.0,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.6,
            "top_p": 1.0
        },
        "provider_name": "together",
        "provider_endpoint": "zai-org/GLM-4.5-Air-FP8",
        "full_key": "together/zai-org/GLM-4.5-Air-FP8",
        "slug": "together_zai-org_GLM-4.5-Air-FP8"
    },
    "fireworks/glm-4p5": {
        "company": "zAI",
        "label": "GLM 4.5",
        "description": "z.AI old model",
        "release_date": "2025-07-28",
        "open_source": true,
        "documentation_url": "https://docs.z.ai/",
        "properties": {
            "context_window": 128000,
            "max_token_output": 81920,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.6,
            "output": 2.2,
            "cache": {
                "read": 0.11,
                "read_discount": 1.0,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.6,
            "top_p": 1.0
        },
        "provider_name": "fireworks",
        "provider_endpoint": "glm-4p5",
        "full_key": "fireworks/glm-4p5",
        "slug": "fireworks_glm-4p5"
    },
    "google/gemini-2.5-flash-lite-thinking": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Lite (Thinking)",
        "description": "Gemini 2.5 Flash-Lite offers ultra-fast, cost-efficient processing at scale, with support for text, images, video, and audio input modalities and large context length.",
        "release_date": "2025-07-22",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65535,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.4,
            "cache": {
                "read": 0.01,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-lite",
        "full_key": "google/gemini-2.5-flash-lite-thinking",
        "slug": "google_gemini-2.5-flash-lite-thinking"
    },
    "google/gemini-2.5-flash-lite": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Lite (Nonthinking)",
        "description": "Gemini 2.5 Flash-Lite offers ultra-fast, cost-efficient processing at scale, with support for text, images, video, and audio input modalities and large context length.",
        "release_date": "2025-07-22",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65535,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.4,
            "cache": {
                "read": 0.01,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "google/gemini-2.5-flash-lite-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-lite",
        "full_key": "google/gemini-2.5-flash-lite",
        "slug": "google_gemini-2.5-flash-lite"
    },
    "google/gemini-2.5-pro": {
        "company": "Google",
        "label": "Gemini 2.5 Pro",
        "description": "Gemini 2.5 Pro is Google's most advanced Gemini model capable of complex reasoning over code, math, STEM problems and analyzing large datasets using multimodal inputs including audio, images, video, and PDFs with a context window exceeding 1 million tokens.",
        "release_date": "2025-07-17",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 10.0,
            "cache": {
                "read": 0.125,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            },
            "context": {
                "threshold": 200000.0,
                "input": 2.5,
                "output": 15.0,
                "cache": {
                    "read": 0.25,
                    "write_markup": 1.0
                }
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-pro",
        "full_key": "google/gemini-2.5-pro",
        "slug": "google_gemini-2.5-pro"
    },
    "google/gemini-2.5-flash-thinking": {
        "company": "Google",
        "label": "Gemini 2.5 Flash (7/17) (Thinking)",
        "description": "Gemini 2.5 Flash is the best price-performance model suitable for large scale processing with support for multiple modalities, a 1 million token context window, and strong reasoning capabilities.",
        "release_date": "2025-07-17",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 2.5,
            "cache": {
                "read": 0.03,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash",
        "full_key": "google/gemini-2.5-flash-thinking",
        "slug": "google_gemini-2.5-flash-thinking"
    },
    "google/gemini-2.5-flash": {
        "company": "Google",
        "label": "Gemini 2.5 Flash (7/17) (Nonthinking)",
        "description": "Gemini 2.5 Flash is the best price-performance model suitable for large scale processing with support for multiple modalities, a 1 million token context window, and strong reasoning capabilities.",
        "release_date": "2025-07-17",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 2.5,
            "cache": {
                "read": 0.03,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "google/gemini-2.5-flash-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash",
        "full_key": "google/gemini-2.5-flash",
        "slug": "google_gemini-2.5-flash"
    },
    "together/moonshotai/Kimi-K2-Instruct": {
        "company": "Kimi",
        "label": "Kimi K2 Instruct",
        "description": "Kimi K2 Instruct",
        "release_date": "2025-07-11",
        "open_source": true,
        "documentation_url": "https://www.kimi.com/",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.0,
            "output": 3.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "together",
        "provider_endpoint": "moonshotai/Kimi-K2-Instruct",
        "full_key": "together/moonshotai/Kimi-K2-Instruct",
        "slug": "together_moonshotai_Kimi-K2-Instruct"
    },
    "grok/grok-4-latest": {
        "company": "xAI",
        "label": "Grok 4",
        "description": "Latest and greatest flagship model offering unparalleled performance in natural language, math and reasoning. The perfect jack of all trades with native tool use and structured outputs support.",
        "release_date": "2025-07-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-4-0709",
        "properties": {
            "context_window": 256000,
            "max_token_output": 128000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.75,
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "context": {
                "threshold": 128000.0,
                "input": 6.0,
                "output": 30.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-4-0709",
        "full_key": "grok/grok-4-latest",
        "slug": "grok_grok-4-latest"
    },
    "grok/grok-4-0709": {
        "company": "xAI",
        "label": "Grok 4",
        "description": "Latest and greatest flagship model offering unparalleled performance in natural language, math and reasoning. The perfect jack of all trades with native tool use and structured outputs support.",
        "release_date": "2025-07-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-4-0709",
        "properties": {
            "context_window": 256000,
            "max_token_output": 128000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.75,
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "context": {
                "threshold": 128000.0,
                "input": 6.0,
                "output": 30.0
            }
        },
        "alternative_keys": [
            "grok/grok-4",
            "grok/grok-4-latest"
        ],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-4-0709",
        "full_key": "grok/grok-4-0709",
        "slug": "grok_grok-4-0709"
    },
    "grok/grok-4": {
        "company": "xAI",
        "label": "Grok 4",
        "description": "Latest and greatest flagship model offering unparalleled performance in natural language, math and reasoning. The perfect jack of all trades with native tool use and structured outputs support.",
        "release_date": "2025-07-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-4-0709",
        "properties": {
            "context_window": 256000,
            "max_token_output": 128000,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.75,
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "context": {
                "threshold": 128000.0,
                "input": 6.0,
                "output": 30.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "max_output_tokens": 128000,
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-4-0709",
        "full_key": "grok/grok-4",
        "slug": "grok_grok-4"
    },
    "ai21labs/jamba-mini-1.7": {
        "company": "AI21 Labs",
        "label": "Jamba 1.7 Mini",
        "description": "The most powerful and efficient long context model",
        "release_date": "2025-07-03",
        "open_source": true,
        "documentation_url": "https://www.ai21.com/jamba",
        "properties": {
            "context_window": 256000,
            "max_token_output": 4096,
            "training_cutoff": "2024-08"
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.4
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.4
        },
        "provider_name": "ai21labs",
        "provider_endpoint": "jamba-mini-1.7",
        "full_key": "ai21labs/jamba-mini-1.7",
        "slug": "ai21labs_jamba-mini-1.7"
    },
    "ai21labs/jamba-large-1.7": {
        "company": "AI21 Labs",
        "label": "Jamba 1.7 Large",
        "description": "The most powerful and efficient long context model",
        "release_date": "2025-07-03",
        "open_source": true,
        "documentation_url": "https://www.ai21.com/jamba",
        "properties": {
            "context_window": 256000,
            "max_token_output": 4096,
            "training_cutoff": "2024-08"
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.4
        },
        "provider_name": "ai21labs",
        "provider_endpoint": "jamba-large-1.7",
        "full_key": "ai21labs/jamba-large-1.7",
        "slug": "ai21labs_jamba-large-1.7"
    },
    "openai/o4-mini-deep-research-2025-06-26": {
        "company": "OpenAI",
        "label": "o4 Mini Deep Research",
        "description": "o4-mini-deep-research is a faster, more affordable deep research model designed for complex, multi-step research tasks.",
        "release_date": "2025-06-26",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o4-mini-deep-research",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2024-05-31",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {
            "deep_research": true
        },
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0,
            "cache": {
                "read": 0.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o4-mini-deep-research-2025-06-26",
        "full_key": "openai/o4-mini-deep-research-2025-06-26",
        "slug": "openai_o4-mini-deep-research-2025-06-26"
    },
    "openai/o4-mini-deep-research": {
        "company": "OpenAI",
        "label": "o4 Mini Deep Research",
        "description": "o4-mini-deep-research is a faster, more affordable deep research model for complex, multi-step research tasks.",
        "release_date": "2025-06-26",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o4-mini-deep-research",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2024-05-31",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {
            "deep_research": true
        },
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0,
            "cache": {
                "read": 0.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o4-mini-deep-research",
        "full_key": "openai/o4-mini-deep-research",
        "slug": "openai_o4-mini-deep-research"
    },
    "openai/o3-deep-research-2025-06-26": {
        "company": "OpenAI",
        "label": "o3 Deep Research",
        "description": "o3-deep-research is OpenAI's most advanced deep-research model, built for complex, multi-step research tasks. It can search and synthesize information from across the internet and from your own data via MCP connectors.",
        "release_date": "2025-06-26",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o3-deep-research",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2024-05-31",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {
            "deep_research": true
        },
        "costs_per_million_token": {
            "input": 10.0,
            "output": 40.0,
            "cache": {
                "read": 2.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o3-deep-research-2025-06-26",
        "full_key": "openai/o3-deep-research-2025-06-26",
        "slug": "openai_o3-deep-research-2025-06-26"
    },
    "openai/o3-deep-research": {
        "company": "OpenAI",
        "label": "o3 Deep Research",
        "description": "o3-deep-research is OpenAI's most advanced deep research model, designed to tackle complex, multi-step research tasks by searching and synthesizing information from across the internet and user data (via MCP connectors).",
        "release_date": "2025-06-26",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o3-deep-research",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2024-05-31",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {
            "deep_research": true
        },
        "costs_per_million_token": {
            "input": 10.0,
            "output": 40.0,
            "cache": {
                "read": 2.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o3-deep-research",
        "full_key": "openai/o3-deep-research",
        "slug": "openai_o3-deep-research"
    },
    "google/gemini-2.5-flash-lite-preview-06-17-thinking": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Lite Preview 6/17 (Thinking)",
        "description": "Gemini 2.5 Flash-Lite offers ultra-fast, cost-efficient processing at scale, with support for text, images, video, and audio input modalities and large context length.",
        "release_date": "2025-06-17",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65535,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.4,
            "cache": {
                "read": 0.01,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-lite-preview-06-17",
        "full_key": "google/gemini-2.5-flash-lite-preview-06-17-thinking",
        "slug": "google_gemini-2.5-flash-lite-preview-06-17-thinking"
    },
    "google/gemini-2.5-flash-lite-preview-06-17": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Lite Preview 6/17 (Nonthinking)",
        "description": "Gemini 2.5 Flash-Lite offers ultra-fast, cost-efficient processing at scale, with support for text, images, video, and audio input modalities and large context length.",
        "release_date": "2025-06-17",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65535,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.4,
            "cache": {
                "read": 0.01,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "google/gemini-2.5-flash-lite-preview-06-17-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-lite-preview-06-17",
        "full_key": "google/gemini-2.5-flash-lite-preview-06-17",
        "slug": "google_gemini-2.5-flash-lite-preview-06-17"
    },
    "openai/o3-pro-2025-06-10": {
        "company": "OpenAI",
        "label": "o3 Pro",
        "description": "o3-pro is a higher-compute version of the o3 family designed for stronger, more consistent reasoning.",
        "release_date": "2025-06-10",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o3-pro",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2024-05-31",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 20.0,
            "output": 80.0,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o3-pro-2025-06-10",
        "full_key": "openai/o3-pro-2025-06-10",
        "slug": "openai_o3-pro-2025-06-10"
    },
    "mistralai/magistral-medium-2506": {
        "company": "Mistral",
        "label": "Magistral Medium 1.0 (06/2025)",
        "description": "Magistral Medium 2506",
        "release_date": "2025-06-10",
        "open_source": false,
        "documentation_url": "https://mistral.ai/news/magistral",
        "properties": {
            "context_window": 131072,
            "max_token_output": 40000,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 5.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "mistralai",
        "provider_endpoint": "magistral-medium-2506",
        "full_key": "mistralai/magistral-medium-2506",
        "slug": "mistralai_magistral-medium-2506"
    },
    "google/gemini-2.5-pro-preview-06-05": {
        "company": "Google",
        "label": "Gemini 2.5 Pro Preview",
        "description": "Gemini 2.5 Pro is Google's most advanced Gemini model capable of complex reasoning over code, math, STEM problems and analyzing large datasets using multimodal inputs including audio, images, video, and PDFs with a context window exceeding 1 million tokens.",
        "release_date": "2025-06-05",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2025-01",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 10.0,
            "cache": {
                "read": 0.125,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-pro-preview-06-05",
        "full_key": "google/gemini-2.5-pro-preview-06-05",
        "slug": "google_gemini-2.5-pro-preview-06-05"
    },
    "bedrock/claude-sonnet-4-20250514-v1-thinking": {
        "company": "Amazon",
        "label": "Claude Sonnet 4 (Thinking)",
        "description": "Anthropic's latest-generation workhorse model, offering a balance of performance and speed.",
        "release_date": "2025-05-22",
        "open_source": false,
        "documentation_url": "https://www.anthropic.com/claude/sonnet",
        "properties": {
            "context_window": 200000,
            "max_token_output": 64000,
            "training_cutoff": "2025-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "bedrock",
        "provider_endpoint": "us.anthropic.claude-sonnet-4-20250514-v1:0-thinking",
        "full_key": "bedrock/claude-sonnet-4-20250514-v1-thinking",
        "slug": "bedrock_claude-sonnet-4-20250514-v1-thinking"
    },
    "bedrock/claude-sonnet-4-20250514-v1": {
        "company": "Amazon",
        "label": "Claude Sonnet 4 (Nonthinking)",
        "description": "Anthropic's latest-generation workhorse model, offering a balance of performance and speed.",
        "release_date": "2025-05-22",
        "open_source": false,
        "documentation_url": "https://www.anthropic.com/claude/sonnet",
        "properties": {
            "context_window": 200000,
            "max_token_output": 64000,
            "training_cutoff": "2025-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "bedrock",
        "provider_endpoint": "us.anthropic.claude-sonnet-4-20250514-v1:0",
        "full_key": "bedrock/claude-sonnet-4-20250514-v1",
        "slug": "bedrock_claude-sonnet-4-20250514-v1"
    },
    "bedrock/claude-opus-4-20250514-v1-thinking": {
        "company": "Amazon",
        "label": "Claude Opus 4 (Thinking)",
        "description": "Anthropic's most powerful model.",
        "release_date": "2025-05-22",
        "open_source": false,
        "documentation_url": "https://docs.anthropic.com/en/docs/models/claude-3-5-sonnet",
        "properties": {
            "context_window": 200000,
            "max_token_output": 32000,
            "training_cutoff": "2025-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "bedrock",
        "provider_endpoint": "us.anthropic.claude-opus-4-20250514-v1:0-thinking",
        "full_key": "bedrock/claude-opus-4-20250514-v1-thinking",
        "slug": "bedrock_claude-opus-4-20250514-v1-thinking"
    },
    "bedrock/claude-opus-4-20250514-v1": {
        "company": "Amazon",
        "label": "Claude Opus 4 (Nonthinking)",
        "description": "Anthropic's most powerful model.",
        "release_date": "2025-05-22",
        "open_source": false,
        "documentation_url": "https://docs.anthropic.com/en/docs/models/claude-3-5-sonnet",
        "properties": {
            "context_window": 200000,
            "max_token_output": 32000,
            "training_cutoff": "2025-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "bedrock",
        "provider_endpoint": "us.anthropic.claude-opus-4-20250514-v1:0",
        "full_key": "bedrock/claude-opus-4-20250514-v1",
        "slug": "bedrock_claude-opus-4-20250514-v1"
    },
    "anthropic/claude-sonnet-4-20250514-thinking": {
        "company": "Anthropic",
        "label": "Claude Sonnet 4 (Thinking)",
        "description": "Balanced high-performance AI for coding, agents, and production workloads, with extended context and reasoning.",
        "release_date": "2025-05-22",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 64000,
            "training_cutoff": "2025-03",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.3,
                "write": 3.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            },
            "context": {
                "threshold": 200000.0,
                "input": 6.0,
                "output": 22.5,
                "cache": {
                    "read": 0.6,
                    "write": 7.5,
                    "write_markup": 1.0
                }
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-sonnet-4-20250514",
        "full_key": "anthropic/claude-sonnet-4-20250514-thinking",
        "slug": "anthropic_claude-sonnet-4-20250514-thinking"
    },
    "anthropic/claude-sonnet-4-20250514": {
        "company": "Anthropic",
        "label": "Claude Sonnet 4 (Nonthinking)",
        "description": "Balanced high-performance AI for coding, agents, and production workloads, with extended context and reasoning.",
        "release_date": "2025-05-22",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 64000,
            "training_cutoff": "2025-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.3,
                "write": 3.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            },
            "context": {
                "threshold": 200000.0,
                "input": 6.0,
                "output": 22.5,
                "cache": {
                    "read": 0.6,
                    "write": 7.5,
                    "write_markup": 1.0
                }
            }
        },
        "alternative_keys": [
            {
                "anthropic/claude-sonnet-4-20250514-thinking": {
                    "properties": {
                        "reasoning_model": true
                    },
                    "class_properties": {
                        "supports_temperature": false
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-sonnet-4-20250514",
        "full_key": "anthropic/claude-sonnet-4-20250514",
        "slug": "anthropic_claude-sonnet-4-20250514"
    },
    "anthropic/claude-opus-4-20250514-thinking": {
        "company": "Anthropic",
        "label": "Claude Opus 4 (Thinking)",
        "description": "Previous flagship for advanced, specialized reasoning and technical agent applications.",
        "release_date": "2025-05-22",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 32000,
            "training_cutoff": "2025-03",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0,
            "cache": {
                "read": 1.5,
                "write": 18.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-opus-4-20250514",
        "full_key": "anthropic/claude-opus-4-20250514-thinking",
        "slug": "anthropic_claude-opus-4-20250514-thinking"
    },
    "anthropic/claude-opus-4-20250514": {
        "company": "Anthropic",
        "label": "Claude Opus 4 (Nonthinking)",
        "description": "Previous flagship for advanced, specialized reasoning and technical agent applications.",
        "release_date": "2025-05-22",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 32000,
            "training_cutoff": "2025-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0,
            "cache": {
                "read": 1.5,
                "write": 18.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "anthropic/claude-opus-4-20250514-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-opus-4-20250514",
        "full_key": "anthropic/claude-opus-4-20250514",
        "slug": "anthropic_claude-opus-4-20250514"
    },
    "google/gemini-2.5-flash-preview-05-20-thinking": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Preview 5/20 (Thinking)",
        "description": "Gemini 2.5 Flash is the best price-performance model suitable for large scale processing with support for multiple modalities, a 1 million token context window, and strong reasoning capabilities.",
        "release_date": "2025-05-20",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2025-01",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6,
            "cache": {
                "read": 0.01,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-preview-05-20",
        "full_key": "google/gemini-2.5-flash-preview-05-20-thinking",
        "slug": "google_gemini-2.5-flash-preview-05-20-thinking"
    },
    "google/gemini-2.5-flash-preview-05-20": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Preview 5/20 (Nonthinking)",
        "description": "Gemini 2.5 Flash is the best price-performance model suitable for large scale processing with support for multiple modalities, a 1 million token context window, and strong reasoning capabilities.",
        "release_date": "2025-05-20",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2025-01",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6,
            "cache": {
                "read": 0.01,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "google/gemini-2.5-flash-preview-05-20-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-preview-05-20",
        "full_key": "google/gemini-2.5-flash-preview-05-20",
        "slug": "google_gemini-2.5-flash-preview-05-20"
    },
    "mistralai/mistral-medium-2505": {
        "company": "Mistral",
        "label": "Mistral Medium 3.1 (05/2025)",
        "description": "Mistral Medium 2505",
        "release_date": "2025-05-07",
        "open_source": false,
        "documentation_url": "https://mistral.ai/news/mistral-medium-3",
        "properties": {
            "context_window": 131072,
            "max_token_output": 32768,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.4,
            "output": 2.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "mistralai",
        "provider_endpoint": "mistral-medium-2505",
        "full_key": "mistralai/mistral-medium-2505",
        "slug": "mistralai_mistral-medium-2505"
    },
    "google/gemini-2.5-pro-preview-05-06": {
        "company": "Google",
        "label": "Gemini 2.5 Pro Preview",
        "description": "Gemini 2.5 Pro is Google's most advanced Gemini model capable of complex reasoning over code, math, STEM problems and analyzing large datasets using multimodal inputs including audio, images, video, and PDFs with a context window exceeding 1 million tokens.",
        "release_date": "2025-05-06",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2025-01",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 10.0,
            "cache": {
                "read": 0.125,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-pro-preview-05-06",
        "full_key": "google/gemini-2.5-pro-preview-05-06",
        "slug": "google_gemini-2.5-pro-preview-05-06"
    },
    "fireworks/qwen3-235b-a22b": {
        "company": "Alibaba",
        "label": "Qwen 3 (235B)",
        "description": "",
        "release_date": "2025-04-28",
        "open_source": true,
        "documentation_url": "https://fireworks.ai/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 32768,
            "training_cutoff": "2024-08",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.22,
            "output": 0.88,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "fireworks",
        "provider_endpoint": "qwen3-235b-a22b",
        "full_key": "fireworks/qwen3-235b-a22b",
        "slug": "fireworks_qwen3-235b-a22b"
    },
    "google/gemini-2.5-flash-preview-04-17-thinking": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Preview 4/17 (Thinking)",
        "description": "Gemini 2.5 Flash is the best price-performance model suitable for large scale processing with support for multiple modalities, a 1 million token context window, and strong reasoning capabilities.",
        "release_date": "2025-04-17",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2025-01",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 2.5,
            "cache": {
                "read": 0.03,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-preview-04-17",
        "full_key": "google/gemini-2.5-flash-preview-04-17-thinking",
        "slug": "google_gemini-2.5-flash-preview-04-17-thinking"
    },
    "google/gemini-2.5-flash-preview-04-17": {
        "company": "Google",
        "label": "Gemini 2.5 Flash Preview 4/17 (Nonthinking)",
        "description": "Gemini 2.5 Flash is the best price-performance model suitable for large scale processing with support for multiple modalities, a 1 million token context window, and strong reasoning capabilities.",
        "release_date": "2025-04-17",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2025-01",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 2.5,
            "cache": {
                "read": 0.03,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "google/gemini-2.5-flash-preview-04-17-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-flash-preview-04-17",
        "full_key": "google/gemini-2.5-flash-preview-04-17",
        "slug": "google_gemini-2.5-flash-preview-04-17"
    },
    "openai/o4-mini-2025-04-16": {
        "company": "OpenAI",
        "label": "o4 Mini",
        "description": "o4-mini is a small, cost-efficient o-series reasoning model optimized for fast, effective reasoning.",
        "release_date": "2025-04-16",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o4-mini",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2024-05-31",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.1,
            "output": 4.4,
            "cache": {
                "read": 0.0275,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/o4-mini-2025-04-16"
        ],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o4-mini-2025-04-16",
        "full_key": "openai/o4-mini-2025-04-16",
        "slug": "openai_o4-mini-2025-04-16"
    },
    "openai/o3-2025-04-16": {
        "company": "OpenAI",
        "label": "o3",
        "description": "o3 is a reasoning model for complex tasks, well-rounded across domains including math, science, coding, and visual reasoning.",
        "release_date": "2025-04-16",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o3",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2024-05-31",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0,
            "cache": {
                "read": 0.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/o3-2025-04-16"
        ],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o3-2025-04-16",
        "full_key": "openai/o3-2025-04-16",
        "slug": "openai_o3-2025-04-16"
    },
    "azure/o4-mini-2025-04-16": {
        "company": "OpenAI",
        "label": "o4 Mini",
        "description": "o4-mini is a small, cost-efficient o-series reasoning model optimized for fast, effective reasoning.",
        "release_date": "2025-04-16",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o4-mini",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2024-05-31",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.1,
            "output": 4.4,
            "cache": {
                "read": 0.0275,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "o4-mini-2025-04-16",
        "full_key": "azure/o4-mini-2025-04-16",
        "slug": "azure_o4-mini-2025-04-16"
    },
    "azure/o3-2025-04-16": {
        "company": "OpenAI",
        "label": "o3",
        "description": "o3 is a reasoning model for complex tasks, well-rounded across domains including math, science, coding, and visual reasoning.",
        "release_date": "2025-04-16",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o3",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2024-05-31",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0,
            "cache": {
                "read": 0.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "o3-2025-04-16",
        "full_key": "azure/o3-2025-04-16",
        "slug": "azure_o3-2025-04-16"
    },
    "openai/gpt-4.1-nano-2025-04-14": {
        "company": "OpenAI",
        "label": "GPT 4.1 Nano",
        "description": "GPT-4.1 nano is the fastest, most cost-efficient version of GPT-4.1 optimized for instruction following and tool calling.",
        "release_date": "2025-04-14",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4.1-nano",
        "properties": {
            "context_window": 1047576,
            "max_token_output": 32768,
            "training_cutoff": "2024-05-31",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.4,
            "cache": {
                "read": 0.025,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/gpt-4.1-nano-2025-04-14"
        ],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4.1-nano-2025-04-14",
        "full_key": "openai/gpt-4.1-nano-2025-04-14",
        "slug": "openai_gpt-4.1-nano-2025-04-14"
    },
    "openai/gpt-4.1-mini-2025-04-14": {
        "company": "OpenAI",
        "label": "GPT 4.1 Mini",
        "description": "GPT-4.1 mini is a smaller, faster version of GPT-4.1 optimized for instruction following and tool calling.",
        "release_date": "2025-04-14",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4.1-mini",
        "properties": {
            "context_window": 1047576,
            "max_token_output": 32768,
            "training_cutoff": "2024-05-31",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.4,
            "output": 1.6,
            "cache": {
                "read": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/gpt-4.1-mini-2025-04-14"
        ],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4.1-mini-2025-04-14",
        "full_key": "openai/gpt-4.1-mini-2025-04-14",
        "slug": "openai_gpt-4.1-mini-2025-04-14"
    },
    "openai/gpt-4.1-2025-04-14": {
        "company": "OpenAI",
        "label": "GPT 4.1",
        "description": "GPT-4.1 is optimized for instruction following and tool calling.",
        "release_date": "2025-04-14",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4.1",
        "properties": {
            "context_window": 1047576,
            "max_token_output": 32768,
            "training_cutoff": "2024-05-31",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0,
            "cache": {
                "read": 0.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/gpt-4.1-2025-04-14"
        ],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4.1-2025-04-14",
        "full_key": "openai/gpt-4.1-2025-04-14",
        "slug": "openai_gpt-4.1-2025-04-14"
    },
    "azure/gpt-4.1-nano-2025-04-14": {
        "company": "OpenAI",
        "label": "GPT 4.1 Nano",
        "description": "GPT-4.1 nano is the fastest, most cost-efficient version of GPT-4.1 optimized for instruction following and tool calling.",
        "release_date": "2025-04-14",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4.1-nano",
        "properties": {
            "context_window": 1047576,
            "max_token_output": 32768,
            "training_cutoff": "2024-05-31",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.4,
            "cache": {
                "read": 0.025,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "gpt-4.1-nano-2025-04-14",
        "full_key": "azure/gpt-4.1-nano-2025-04-14",
        "slug": "azure_gpt-4.1-nano-2025-04-14"
    },
    "azure/gpt-4.1-mini-2025-04-14": {
        "company": "OpenAI",
        "label": "GPT 4.1 Mini",
        "description": "GPT-4.1 mini is a smaller, faster version of GPT-4.1 optimized for instruction following and tool calling.",
        "release_date": "2025-04-14",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4.1-mini",
        "properties": {
            "context_window": 1047576,
            "max_token_output": 32768,
            "training_cutoff": "2024-05-31",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.4,
            "output": 1.6,
            "cache": {
                "read": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "gpt-4.1-mini-2025-04-14",
        "full_key": "azure/gpt-4.1-mini-2025-04-14",
        "slug": "azure_gpt-4.1-mini-2025-04-14"
    },
    "azure/gpt-4.1-2025-04-14": {
        "company": "OpenAI",
        "label": "GPT 4.1",
        "description": "GPT-4.1 is optimized for instruction following and tool calling.",
        "release_date": "2025-04-14",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4.1",
        "properties": {
            "context_window": 1047576,
            "max_token_output": 32768,
            "training_cutoff": "2024-05-31",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0,
            "cache": {
                "read": 0.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "gpt-4.1-2025-04-14",
        "full_key": "azure/gpt-4.1-2025-04-14",
        "slug": "azure_gpt-4.1-2025-04-14"
    },
    "grok/grok-3-mini-low-reasoning": {
        "company": "xAI",
        "label": "Grok 3 Mini Reasoning",
        "description": "Compact reasoning model supporting reasoning effort parameter. Balances performance and efficiency for various tasks.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3-mini",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "reasoning_effort": "low"
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3-mini",
        "full_key": "grok/grok-3-mini-low-reasoning",
        "slug": "grok_grok-3-mini-low-reasoning"
    },
    "grok/grok-3-mini-latest": {
        "company": "xAI",
        "label": "Grok 3 Mini Reasoning",
        "description": "Compact reasoning model supporting reasoning effort parameter. Balances performance and efficiency for various tasks.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3-mini",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3-mini",
        "full_key": "grok/grok-3-mini-latest",
        "slug": "grok_grok-3-mini-latest"
    },
    "grok/grok-3-mini-high-reasoning": {
        "company": "xAI",
        "label": "Grok 3 Mini Reasoning",
        "description": "Compact reasoning model supporting reasoning effort parameter. Balances performance and efficiency for various tasks.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3-mini",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "reasoning_effort": "high"
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3-mini",
        "full_key": "grok/grok-3-mini-high-reasoning",
        "slug": "grok_grok-3-mini-high-reasoning"
    },
    "grok/grok-3-mini-fast-low-reasoning": {
        "company": "xAI",
        "label": "Grok 3 Mini Reasoning",
        "description": "Compact reasoning model supporting reasoning effort parameter. Balances performance and efficiency for various tasks.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3-mini",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "reasoning_effort": "low"
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3-mini",
        "full_key": "grok/grok-3-mini-fast-low-reasoning",
        "slug": "grok_grok-3-mini-fast-low-reasoning"
    },
    "grok/grok-3-mini-fast-latest": {
        "company": "xAI",
        "label": "Grok 3 Mini Reasoning",
        "description": "Compact reasoning model supporting reasoning effort parameter. Balances performance and efficiency for various tasks.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3-mini",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3-mini",
        "full_key": "grok/grok-3-mini-fast-latest",
        "slug": "grok_grok-3-mini-fast-latest"
    },
    "grok/grok-3-mini-fast-high-reasoning": {
        "company": "xAI",
        "label": "Grok 3 Mini Reasoning",
        "description": "Compact reasoning model supporting reasoning effort parameter. Balances performance and efficiency for various tasks.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3-mini",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "reasoning_effort": "high"
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3-mini",
        "full_key": "grok/grok-3-mini-fast-high-reasoning",
        "slug": "grok_grok-3-mini-fast-high-reasoning"
    },
    "grok/grok-3-mini-fast-beta": {
        "company": "xAI",
        "label": "Grok 3 Mini Reasoning",
        "description": "Compact reasoning model supporting reasoning effort parameter. Balances performance and efficiency for various tasks.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3-mini",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3-mini",
        "full_key": "grok/grok-3-mini-fast-beta",
        "slug": "grok_grok-3-mini-fast-beta"
    },
    "grok/grok-3-mini-fast": {
        "company": "xAI",
        "label": "Grok 3 Mini Reasoning",
        "description": "Compact reasoning model supporting reasoning effort parameter. Balances performance and efficiency for various tasks.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3-mini",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3-mini",
        "full_key": "grok/grok-3-mini-fast",
        "slug": "grok_grok-3-mini-fast"
    },
    "grok/grok-3-mini-beta": {
        "company": "xAI",
        "label": "Grok 3 Mini Reasoning",
        "description": "Compact reasoning model supporting reasoning effort parameter. Balances performance and efficiency for various tasks.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3-mini",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3-mini",
        "full_key": "grok/grok-3-mini-beta",
        "slug": "grok_grok-3-mini-beta"
    },
    "grok/grok-3-mini": {
        "company": "xAI",
        "label": "Grok 3 Mini Reasoning",
        "description": "Compact reasoning model supporting reasoning effort parameter. Balances performance and efficiency for various tasks.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3-mini",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [
            "grok/grok-3-mini-latest",
            "grok/grok-3-mini-beta",
            "grok/grok-3-mini-fast",
            "grok/grok-3-mini-fast-latest",
            "grok/grok-3-mini-fast-beta",
            {
                "grok/grok-3-mini-high-reasoning": {
                    "default_parameters": {
                        "reasoning_effort": "high"
                    }
                }
            },
            {
                "grok/grok-3-mini-low-reasoning": {
                    "default_parameters": {
                        "reasoning_effort": "low"
                    }
                }
            },
            {
                "grok/grok-3-mini-fast-high-reasoning": {
                    "default_parameters": {
                        "reasoning_effort": "high"
                    }
                }
            },
            {
                "grok/grok-3-mini-fast-low-reasoning": {
                    "default_parameters": {
                        "reasoning_effort": "low"
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3-mini",
        "full_key": "grok/grok-3-mini",
        "slug": "grok_grok-3-mini"
    },
    "grok/grok-3-latest": {
        "company": "xAI",
        "label": "Grok 3",
        "description": "Excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.75,
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3",
        "full_key": "grok/grok-3-latest",
        "slug": "grok_grok-3-latest"
    },
    "grok/grok-3-fast-latest": {
        "company": "xAI",
        "label": "Grok 3",
        "description": "Excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.75,
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3",
        "full_key": "grok/grok-3-fast-latest",
        "slug": "grok_grok-3-fast-latest"
    },
    "grok/grok-3-fast-beta": {
        "company": "xAI",
        "label": "Grok 3",
        "description": "Excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.75,
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3",
        "full_key": "grok/grok-3-fast-beta",
        "slug": "grok_grok-3-fast-beta"
    },
    "grok/grok-3-fast": {
        "company": "xAI",
        "label": "Grok 3",
        "description": "Excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.75,
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3",
        "full_key": "grok/grok-3-fast",
        "slug": "grok_grok-3-fast"
    },
    "grok/grok-3-beta": {
        "company": "xAI",
        "label": "Grok 3",
        "description": "Excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.75,
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3",
        "full_key": "grok/grok-3-beta",
        "slug": "grok_grok-3-beta"
    },
    "grok/grok-3": {
        "company": "xAI",
        "label": "Grok 3",
        "description": "Excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.",
        "release_date": "2025-04-09",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs/models/grok-3",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.75,
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [
            "grok/grok-3-latest",
            "grok/grok-3-beta",
            "grok/grok-3-fast",
            "grok/grok-3-fast-latest",
            "grok/grok-3-fast-beta"
        ],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-3",
        "full_key": "grok/grok-3",
        "slug": "grok_grok-3"
    },
    "together/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
        "company": "Meta",
        "label": "Llama 4 Scout",
        "description": "Llama 4 Scout 17B 16E Instruct FP8",
        "release_date": "2025-04-05",
        "open_source": true,
        "documentation_url": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
        "properties": {
            "context_window": 10000000,
            "max_token_output": 16384,
            "training_cutoff": "2024-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.59
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "full_key": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "slug": "together_meta-llama_Llama-4-Scout-17B-16E-Instruct"
    },
    "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
        "company": "Meta",
        "label": "Llama 4 Maverick",
        "description": "Llama 4 Maverick 17B 128E Instruct FP8",
        "release_date": "2025-04-05",
        "open_source": true,
        "documentation_url": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
        "properties": {
            "context_window": 1000000,
            "max_token_output": 16384,
            "training_cutoff": "2024-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.27,
            "output": 0.85
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "full_key": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "slug": "together_meta-llama_Llama-4-Maverick-17B-128E-Instruct-FP8"
    },
    "google/gemini-2.5-pro-preview-03-25": {
        "company": "Google",
        "label": "Gemini 2.5 Pro Preview",
        "description": "Gemini 2.5 Pro is Google's most advanced Gemini model capable of complex reasoning over code, math, STEM problems and analyzing large datasets using multimodal inputs including audio, images, video, and PDFs with a context window exceeding 1 million tokens.",
        "release_date": "2025-04-05",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2025-01",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 10.0,
            "cache": {
                "read": 0.125,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-pro-preview-03-25",
        "full_key": "google/gemini-2.5-pro-preview-03-25",
        "slug": "google_gemini-2.5-pro-preview-03-25"
    },
    "fireworks/llama4-scout-instruct-basic": {
        "company": "Meta",
        "label": "Llama 4 Scout",
        "description": "Llama 4 Scout SOTA 128-expert MoE powerhouse for multilingual image/text understanding.",
        "release_date": "2025-04-05",
        "open_source": true,
        "documentation_url": "https://fireworks.ai/models",
        "properties": {
            "context_window": 10000000,
            "max_token_output": 16384,
            "training_cutoff": "2024-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.59,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "fireworks",
        "provider_endpoint": "llama4-scout-instruct-basic",
        "full_key": "fireworks/llama4-scout-instruct-basic",
        "slug": "fireworks_llama4-scout-instruct-basic"
    },
    "fireworks/llama4-maverick-instruct-basic": {
        "company": "Meta",
        "label": "Llama 4 Maverick",
        "description": "Llama 4 Maverick SOTA 128-expert MoE powerhouse for multilingual image/text understanding.",
        "release_date": "2025-04-05",
        "open_source": true,
        "documentation_url": "https://fireworks.ai/models",
        "properties": {
            "context_window": 1000000,
            "max_token_output": 16384,
            "training_cutoff": "2024-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.22,
            "output": 0.88,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "fireworks",
        "provider_endpoint": "llama4-maverick-instruct-basic",
        "full_key": "fireworks/llama4-maverick-instruct-basic",
        "slug": "fireworks_llama4-maverick-instruct-basic"
    },
    "google/gemini-2.5-pro-exp-03-25": {
        "company": "Google",
        "label": "Gemini 2.5 Pro Exp",
        "description": "Gemini 2.5 Pro is Google's most advanced Gemini model capable of complex reasoning over code, math, STEM problems and analyzing large datasets using multimodal inputs including audio, images, video, and PDFs with a context window exceeding 1 million tokens.",
        "release_date": "2025-03-25",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2025-01",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 10.0,
            "cache": {
                "read": 0.125,
                "read_discount": 0.1,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "google",
        "provider_endpoint": "gemini-2.5-pro-exp-03-25",
        "full_key": "google/gemini-2.5-pro-exp-03-25",
        "slug": "google_gemini-2.5-pro-exp-03-25"
    },
    "fireworks/deepseek-v3-0324": {
        "company": "DeepSeek",
        "label": "DeepSeek V3 (03/24/2025)",
        "description": "",
        "release_date": "2025-03-24",
        "open_source": true,
        "documentation_url": "https://fireworks.ai/models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 131072,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 1.2,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "fireworks",
        "provider_endpoint": "deepseek-v3-0324",
        "full_key": "fireworks/deepseek-v3-0324",
        "slug": "fireworks_deepseek-v3-0324"
    },
    "mistralai/mistral-small-2503": {
        "company": "Mistral",
        "label": "Mistral Small 3.1 (03/2025)",
        "description": "Mistral Small 2503",
        "release_date": "2025-03-17",
        "open_source": false,
        "documentation_url": "https://mistral.ai/news/mistral-small-3-1",
        "properties": {
            "context_window": 131072,
            "max_token_output": 8192,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.075,
            "output": 0.3
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "mistralai",
        "provider_endpoint": "mistral-small-2503",
        "full_key": "mistralai/mistral-small-2503",
        "slug": "mistralai_mistral-small-2503"
    },
    "cohere/command-a-03-2025": {
        "company": "Cohere",
        "label": "Command A",
        "description": "Command A is Cohere's most performant model to date, excelling at tool use, agents, retrieval augmented generation (RAG), and multilingual use cases. It supports a context length of 256K tokens with high throughput.",
        "release_date": "2025-03-13",
        "open_source": false,
        "documentation_url": "https://docs.cohere.com/v2/docs/models",
        "properties": {
            "context_window": 256000,
            "max_token_output": 8000,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.5,
            "output": 10.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "cohere",
        "provider_endpoint": "command-a-03-2025",
        "full_key": "cohere/command-a-03-2025",
        "slug": "cohere_command-a-03-2025"
    },
    "google/gemma-3-27b-it": {
        "company": "Google",
        "label": "Gemma 3 27B it",
        "description": "Gemma 3 is an open generative AI model optimized for everyday device use such as phones and tablets, capable of handling text, audio, and vision inputs with efficient parameter caching techniques.",
        "release_date": "2025-03-12",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 8192,
            "training_cutoff": "2023-09",
            "reasoning_model": false
        },
        "class_properties": {
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.0,
            "output": 0.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemma-3-27b-it",
        "full_key": "google/gemma-3-27b-it",
        "slug": "google_gemma-3-27b-it"
    },
    "ai21labs/jamba-mini-1.6": {
        "company": "AI21 Labs",
        "label": "Jamba 1.6 Mini",
        "description": "The most powerful and efficient long context model",
        "release_date": "2025-03-06",
        "open_source": true,
        "documentation_url": "https://www.ai21.com/jamba",
        "properties": {
            "context_window": 256000,
            "max_token_output": 4096,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.4
        },
        "alternative_keys": [
            "ai21labs/jamba-1.6-mini"
        ],
        "default_parameters": {
            "temperature": 0.4
        },
        "provider_name": "ai21labs",
        "provider_endpoint": "jamba-mini-1.6",
        "full_key": "ai21labs/jamba-mini-1.6",
        "slug": "ai21labs_jamba-mini-1.6"
    },
    "ai21labs/jamba-large-1.6": {
        "company": "AI21 Labs",
        "label": "Jamba 1.6 Large",
        "description": "The most powerful and efficient long context model",
        "release_date": "2025-03-06",
        "open_source": true,
        "documentation_url": "https://www.ai21.com/jamba",
        "properties": {
            "context_window": 256000,
            "max_token_output": 4096,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0
        },
        "alternative_keys": [
            "ai21labs/jamba-1.6-large"
        ],
        "default_parameters": {
            "temperature": 0.4
        },
        "provider_name": "ai21labs",
        "provider_endpoint": "jamba-large-1.6",
        "full_key": "ai21labs/jamba-large-1.6",
        "slug": "ai21labs_jamba-large-1.6"
    },
    "ai21labs/jamba-1.6-mini": {
        "company": "AI21 Labs",
        "label": "Jamba 1.6 Mini",
        "description": "The most powerful and efficient long context model",
        "release_date": "2025-03-06",
        "open_source": true,
        "documentation_url": "https://www.ai21.com/jamba",
        "properties": {
            "context_window": 256000,
            "max_token_output": 4096,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.4
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.4
        },
        "provider_name": "ai21labs",
        "provider_endpoint": "jamba-mini-1.6",
        "full_key": "ai21labs/jamba-1.6-mini",
        "slug": "ai21labs_jamba-1.6-mini"
    },
    "ai21labs/jamba-1.6-large": {
        "company": "AI21 Labs",
        "label": "Jamba 1.6 Large",
        "description": "The most powerful and efficient long context model",
        "release_date": "2025-03-06",
        "open_source": true,
        "documentation_url": "https://www.ai21.com/jamba",
        "properties": {
            "context_window": 256000,
            "max_token_output": 4096,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.4
        },
        "provider_name": "ai21labs",
        "provider_endpoint": "jamba-large-1.6",
        "full_key": "ai21labs/jamba-1.6-large",
        "slug": "ai21labs_jamba-1.6-large"
    },
    "bedrock/deepseek-r1-v1": {
        "company": "Amazon",
        "label": "DeepSeek R1 (Bedrock)",
        "description": "DeepSeek R1, hosted on Bedrock.",
        "release_date": "2025-03-03",
        "open_source": false,
        "documentation_url": "https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-deepseek.html",
        "properties": {
            "context_window": 128000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.35,
            "output": 5.4
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "bedrock",
        "provider_endpoint": "us.deepseek.r1-v1:0",
        "full_key": "bedrock/deepseek-r1-v1",
        "slug": "bedrock_deepseek-r1-v1"
    },
    "openai/gpt-4.5-preview-2025-02-27": {
        "company": "OpenAI",
        "label": "GPT 4.5 Preview",
        "description": "GPT-4.5 Preview is a research preview and deprecated large model.",
        "release_date": "2025-02-27",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4.5-preview",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": "2023-10",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 75.0,
            "output": 150.0,
            "cache": {
                "read": 37.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4.5-preview-2025-02-27",
        "full_key": "openai/gpt-4.5-preview-2025-02-27",
        "slug": "openai_gpt-4.5-preview-2025-02-27"
    },
    "anthropic/claude-3-7-sonnet-20250219-thinking": {
        "company": "Anthropic",
        "label": "Claude 3.7 Sonnet (Thinking)",
        "description": "Hybrid reasoning agent, high intelligence, vision inputs, and fast code/content generation.",
        "release_date": "2025-02-24",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 8192,
            "training_cutoff": "2024-08",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.3,
                "write": 3.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-7-sonnet-20250219",
        "full_key": "anthropic/claude-3-7-sonnet-20250219-thinking",
        "slug": "anthropic_claude-3-7-sonnet-20250219-thinking"
    },
    "anthropic/claude-3-7-sonnet-20250219": {
        "company": "Anthropic",
        "label": "Claude 3.7 Sonnet (Nonthinking)",
        "description": "Hybrid reasoning agent, high intelligence, vision inputs, and fast code/content generation.",
        "release_date": "2025-02-24",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 8192,
            "training_cutoff": "2024-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.3,
                "write": 3.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            {
                "anthropic/claude-3-7-sonnet-20250219-thinking": {
                    "properties": {
                        "reasoning_model": true
                    }
                }
            }
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-7-sonnet-20250219",
        "full_key": "anthropic/claude-3-7-sonnet-20250219",
        "slug": "anthropic_claude-3-7-sonnet-20250219"
    },
    "bedrock/claude-3-7-sonnet-20250219-v1": {
        "company": "Amazon",
        "label": "Claude 3.7 Sonnet (Bedrock)",
        "description": "Claude 3.7 Sonnet, hosted on Bedrock.",
        "release_date": "2025-02-19",
        "open_source": false,
        "documentation_url": "https://docs.anthropic.com/en/docs/models/claude-3-5-sonnet",
        "properties": {
            "context_window": 200000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read": 0.3,
                "write": 3.75,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "bedrock",
        "provider_endpoint": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
        "full_key": "bedrock/claude-3-7-sonnet-20250219-v1",
        "slug": "bedrock_claude-3-7-sonnet-20250219-v1"
    },
    "google/gemini-2.0-pro-exp-02-05": {
        "company": "Google",
        "label": "Gemini 2.0 Pro Exp",
        "description": "Gemini 2.0 Pro is a powerful second-generation model optimized for large context processing and multimodal inputs, with strengths in speed, native tool use, and dataset comprehension.",
        "release_date": "2025-02-05",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 2097152,
            "max_token_output": 8192,
            "training_cutoff": "2024-06",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 5.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-2.0-pro-exp-02-05",
        "full_key": "google/gemini-2.0-pro-exp-02-05",
        "slug": "google_gemini-2.0-pro-exp-02-05"
    },
    "google/gemini-2.0-flash-001": {
        "company": "Google",
        "label": "Gemini 2.0 Flash (001)",
        "description": "Gemini 2.0 Flash is a fast and versatile second-generation model with a 1 million token context window and support for text, image, video, and audio inputs.",
        "release_date": "2025-02-05",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 8192,
            "training_cutoff": "2024-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.4,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-2.0-flash-001",
        "full_key": "google/gemini-2.0-flash-001",
        "slug": "google_gemini-2.0-flash-001"
    },
    "openai/o3-mini-2025-01-31": {
        "company": "OpenAI",
        "label": "o3 Mini",
        "description": "o3-mini is a small model alternative to o3.",
        "release_date": "2025-01-31",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o3-mini",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.1,
            "output": 4.4,
            "cache": {
                "read": 0.55,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/o3-mini-2025-01-31"
        ],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o3-mini-2025-01-31",
        "full_key": "openai/o3-mini-2025-01-31",
        "slug": "openai_o3-mini-2025-01-31"
    },
    "openai/o3-mini": {
        "company": "OpenAI",
        "label": "o3 Mini",
        "description": "o3-mini \u2014 a small model alternative to o3.",
        "release_date": "2025-01-31",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o3-mini",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.1,
            "output": 4.4,
            "cache": {
                "read": 0.55,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o3-mini",
        "full_key": "openai/o3-mini",
        "slug": "openai_o3-mini"
    },
    "azure/o3-mini-2025-01-31": {
        "company": "OpenAI",
        "label": "o3 Mini",
        "description": "o3-mini is a small model alternative to o3.",
        "release_date": "2025-01-31",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o3-mini",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.1,
            "output": 4.4,
            "cache": {
                "read": 0.55,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "o3-mini-2025-01-31",
        "full_key": "azure/o3-mini-2025-01-31",
        "slug": "azure_o3-mini-2025-01-31"
    },
    "google/gemini-2.0-flash-thinking-exp-01-21": {
        "company": "Google",
        "label": "Gemini 2.0 Flash Thinking Exp",
        "description": "Gemini 2.0 Flash Thinking is an experimental variant optimized for reasoning and longer contextual memory in multimodal scenarios including text, images, video, and audio.",
        "release_date": "2025-01-21",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 65536,
            "training_cutoff": "2024-05",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.7,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-2.0-flash-thinking-exp-01-21",
        "full_key": "google/gemini-2.0-flash-thinking-exp-01-21",
        "slug": "google_gemini-2.0-flash-thinking-exp-01-21"
    },
    "together/deepseek-ai/DeepSeek-R1": {
        "company": "DeepSeek",
        "label": "DeepSeek V3",
        "description": "",
        "release_date": "2025-01-20",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 163840,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 7.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "together",
        "provider_endpoint": "deepseek-ai/DeepSeek-R1",
        "full_key": "together/deepseek-ai/DeepSeek-R1",
        "slug": "together_deepseek-ai_DeepSeek-R1"
    },
    "fireworks/deepseek-r1": {
        "company": "DeepSeek",
        "label": "DeepSeek R1",
        "description": "",
        "release_date": "2025-01-20",
        "open_source": true,
        "documentation_url": "https://fireworks.ai/models",
        "properties": {
            "context_window": 163840,
            "max_token_output": 163840,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 8.0,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "fireworks",
        "provider_endpoint": "deepseek-r1",
        "full_key": "fireworks/deepseek-r1",
        "slug": "fireworks_deepseek-r1"
    },
    "together/deepseek-ai/DeepSeek-V3": {
        "company": "DeepSeek",
        "label": "DeepSeek V3",
        "description": "",
        "release_date": "2024-12-26",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 1.25
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "together",
        "provider_endpoint": "deepseek-ai/DeepSeek-V3",
        "full_key": "together/deepseek-ai/DeepSeek-V3",
        "slug": "together_deepseek-ai_DeepSeek-V3"
    },
    "fireworks/deepseek-v3": {
        "company": "DeepSeek",
        "label": "DeepSeek V3",
        "description": "",
        "release_date": "2024-12-26",
        "open_source": true,
        "documentation_url": "https://fireworks.ai/models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 131072,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "fireworks",
        "provider_endpoint": "deepseek-v3",
        "full_key": "fireworks/deepseek-v3",
        "slug": "fireworks_deepseek-v3"
    },
    "bedrock/llama3-3-70b-instruct-v1": {
        "company": "Amazon",
        "label": "Llama 3.3 70B Instruct (Bedrock)",
        "description": "Llama 3.3 70B Instruct, hosted on Bedrock.",
        "release_date": "2024-12-18",
        "open_source": false,
        "documentation_url": "https://aws.amazon.com/bedrock/meta/",
        "properties": {
            "context_window": 128000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.72,
            "output": 0.72
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "bedrock",
        "provider_endpoint": "us.meta.llama3-3-70b-instruct-v1:0",
        "full_key": "bedrock/llama3-3-70b-instruct-v1",
        "slug": "bedrock_llama3-3-70b-instruct-v1"
    },
    "openai/o1-2024-12-17": {
        "company": "OpenAI",
        "label": "o1",
        "description": "o1 is a previous full o-series reasoning model trained with reinforcement learning to perform complex reasoning.",
        "release_date": "2024-12-17",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o1",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 60.0,
            "cache": {
                "read": 7.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "openai/o1",
            "azure/o1-2024-12-17"
        ],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o1-2024-12-17",
        "full_key": "openai/o1-2024-12-17",
        "slug": "openai_o1-2024-12-17"
    },
    "openai/o1": {
        "company": "OpenAI",
        "label": "o1",
        "description": "o1 is a previous full o-series reasoning model trained with reinforcement learning to perform complex reasoning.",
        "release_date": "2024-12-17",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o1",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 60.0,
            "cache": {
                "read": 7.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o1-2024-12-17",
        "full_key": "openai/o1",
        "slug": "openai_o1"
    },
    "azure/o1-2024-12-17": {
        "company": "OpenAI",
        "label": "o1",
        "description": "o1 is a previous full o-series reasoning model trained with reinforcement learning to perform complex reasoning.",
        "release_date": "2024-12-17",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o1",
        "properties": {
            "context_window": 200000,
            "max_token_output": 100000,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 60.0,
            "cache": {
                "read": 7.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "o1-2024-12-17",
        "full_key": "azure/o1-2024-12-17",
        "slug": "azure_o1-2024-12-17"
    },
    "cohere/command-r7b-12-2024": {
        "company": "Cohere",
        "label": "Command R7B",
        "description": "Command R7B is a small, fast update from December 2024. It excels at RAG, tool use, agents, and complex reasoning with multiple steps. It supports a context length of 128K tokens.",
        "release_date": "2024-12-13",
        "open_source": false,
        "documentation_url": "https://docs.cohere.com/v2/docs/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4000,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.0375,
            "output": 0.15
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "cohere",
        "provider_endpoint": "command-r7b-12-2024",
        "full_key": "cohere/command-r7b-12-2024",
        "slug": "cohere_command-r7b-12-2024"
    },
    "grok/grok-vision-beta": {
        "company": "xAI",
        "label": "Grok Vision Beta",
        "description": "",
        "release_date": "2024-12-12",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs#models",
        "properties": {
            "context_window": 8192,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 5.0,
            "output": 15.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-vision-beta",
        "full_key": "grok/grok-vision-beta",
        "slug": "grok_grok-vision-beta"
    },
    "grok/grok-2-vision-latest": {
        "company": "xAI",
        "label": "Grok 2 Vision",
        "description": "",
        "release_date": "2024-12-12",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs#models",
        "properties": {
            "context_window": 8192,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 10.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-2-vision-1212",
        "full_key": "grok/grok-2-vision-latest",
        "slug": "grok_grok-2-vision-latest"
    },
    "grok/grok-2-vision-1212": {
        "company": "xAI",
        "label": "Grok 2 Vision",
        "description": "",
        "release_date": "2024-12-12",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs#models",
        "properties": {
            "context_window": 8192,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 10.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [
            "grok/grok-2-vision",
            "grok/grok-2-vision-latest"
        ],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-2-vision-1212",
        "full_key": "grok/grok-2-vision-1212",
        "slug": "grok_grok-2-vision-1212"
    },
    "grok/grok-2-vision": {
        "company": "xAI",
        "label": "Grok 2 Vision",
        "description": "",
        "release_date": "2024-12-12",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs#models",
        "properties": {
            "context_window": 8192,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 10.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-2-vision-1212",
        "full_key": "grok/grok-2-vision",
        "slug": "grok_grok-2-vision"
    },
    "grok/grok-beta": {
        "company": "xAI",
        "label": "Grok Beta",
        "description": "",
        "release_date": "2024-12-11",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs#models",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 5.0,
            "output": 15.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-beta",
        "full_key": "grok/grok-beta",
        "slug": "grok_grok-beta"
    },
    "grok/grok-2-1212": {
        "company": "xAI",
        "label": "Grok 2",
        "description": "",
        "release_date": "2024-12-11",
        "open_source": false,
        "documentation_url": "https://docs.x.ai/docs#models",
        "properties": {
            "context_window": 131072,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 10.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7,
            "top_p": 0.95
        },
        "provider_name": "grok",
        "provider_endpoint": "grok-2-1212",
        "full_key": "grok/grok-2-1212",
        "slug": "grok_grok-2-1212"
    },
    "google/gemini-2.0-flash-exp": {
        "company": "Google",
        "label": "Gemini 2.0 Flash Exp",
        "description": "Gemini 2.0 Flash Experimental is a developer preview for advanced use cases requiring extended context and multimodal reasoning capabilities.",
        "release_date": "2024-12-11",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 8192,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.075,
            "output": 0.3,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-2.0-flash-exp",
        "full_key": "google/gemini-2.0-flash-exp",
        "slug": "google_gemini-2.0-flash-exp"
    },
    "together/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
        "company": "Meta",
        "label": "Llama 3.3 Instruct Turbo (70B)",
        "description": "Llama 3.3 Instruct Turbo, 70B parameters with FP16 quantization.",
        "release_date": "2024-12-06",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.88,
            "output": 0.88
        },
        "alternative_keys": [
            "together/llama-3.3-70b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
        "full_key": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo",
        "slug": "together_meta-llama_Llama-3.3-70B-Instruct-Turbo"
    },
    "together/llama-3.3-70b-instruct": {
        "company": "Meta",
        "label": "Llama 3.3 Instruct Turbo (70B)",
        "description": "Llama 3.3 Instruct Turbo, 70B parameters with FP16 quantization.",
        "release_date": "2024-12-06",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.88,
            "output": 0.88
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
        "full_key": "together/llama-3.3-70b-instruct",
        "slug": "together_llama-3.3-70b-instruct"
    },
    "amazon/amazon.nova-pro-v1:0": {
        "company": "Amazon",
        "label": "Nova Pro",
        "description": "Highly capable multimodal model offering the best combination of accuracy, speed, and cost for a wide range of tasks.",
        "release_date": "2024-12-03",
        "open_source": false,
        "documentation_url": "https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html",
        "properties": {
            "context_window": 300000,
            "max_token_output": 10000,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 3.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "amazon",
        "provider_endpoint": "amazon.nova-pro-v1:0",
        "full_key": "amazon/amazon.nova-pro-v1:0",
        "slug": "amazon_amazon.nova-pro-v1:0"
    },
    "amazon/amazon.nova-micro-v1:0": {
        "company": "Amazon",
        "label": "Nova Micro",
        "description": "Text-only model that delivers the lowest latency responses at very low cost. Features 128k token context window and supports 200+ languages, optimized for 15 key languages.",
        "release_date": "2024-12-03",
        "open_source": false,
        "documentation_url": "https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html",
        "properties": {
            "context_window": 128000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.035,
            "output": 0.14
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "amazon",
        "provider_endpoint": "amazon.nova-micro-v1:0",
        "full_key": "amazon/amazon.nova-micro-v1:0",
        "slug": "amazon_amazon.nova-micro-v1:0"
    },
    "amazon/amazon.nova-lite-v1:0": {
        "company": "Amazon",
        "label": "Nova Lite",
        "description": "Very low cost multimodal model that is lightning fast for processing image, video, and text inputs. Features 300k token context window and supports document processing. Optimized for 15 languages.",
        "release_date": "2024-12-03",
        "open_source": false,
        "documentation_url": "https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html",
        "properties": {
            "context_window": 300000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.06,
            "output": 0.24
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "amazon",
        "provider_endpoint": "amazon.nova-lite-v1:0",
        "full_key": "amazon/amazon.nova-lite-v1:0",
        "slug": "amazon_amazon.nova-lite-v1:0"
    },
    "openai/gpt-4o-2024-11-20": {
        "company": "OpenAI",
        "label": "GPT 4o (2024-11-20)",
        "description": "GPT-4o is a fast, intelligent, flexible GPT model that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-11-20",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4o",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": "2023-10",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 5.0,
            "output": 15.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/gpt-4o-2024-11-20"
        ],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4o-2024-11-20",
        "full_key": "openai/gpt-4o-2024-11-20",
        "slug": "openai_gpt-4o-2024-11-20"
    },
    "azure/gpt-4o-2024-11-20": {
        "company": "OpenAI",
        "label": "GPT 4o (2024-11-20)",
        "description": "GPT-4o is a fast, intelligent, flexible GPT model that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-11-20",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4o",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": "2023-10",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 5.0,
            "output": 15.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "gpt-4o-2024-11-20",
        "full_key": "azure/gpt-4o-2024-11-20",
        "slug": "azure_gpt-4o-2024-11-20"
    },
    "mistralai/pixtral-large-2411": {
        "company": "Mistral",
        "label": "Pixtral Large (11/2024)",
        "description": "Latest version of the Pixtral Large model.",
        "release_date": "2024-11-18",
        "open_source": false,
        "documentation_url": "https://docs.mistral.ai/getting-started/models/models_overview/",
        "properties": {
            "context_window": 128000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 6.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "mistralai",
        "provider_endpoint": "pixtral-large-2411",
        "full_key": "mistralai/pixtral-large-2411",
        "slug": "mistralai_pixtral-large-2411"
    },
    "mistralai/mistral-large-2411": {
        "company": "Mistral",
        "label": "Mistral Large (11/2024)",
        "description": "Latest version of the Mistral Large model.",
        "release_date": "2024-11-18",
        "open_source": false,
        "documentation_url": "https://docs.mistral.ai/getting-started/models/models_overview/",
        "properties": {
            "context_window": 128000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 6.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "mistralai",
        "provider_endpoint": "mistral-large-2411",
        "full_key": "mistralai/mistral-large-2411",
        "slug": "mistralai_mistral-large-2411"
    },
    "openai/gpt-4-1106-preview": {
        "company": "OpenAI",
        "label": "GPT 4 Preview (2023-11-06)",
        "description": "GPT-4 Turbo preview model featuring improved instruction following, JSON mode, and reproducible outputs.",
        "release_date": "2024-11-06",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4096,
            "training_cutoff": "2023-04",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 10.0,
            "output": 30.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4-1106-preview",
        "full_key": "openai/gpt-4-1106-preview",
        "slug": "openai_gpt-4-1106-preview"
    },
    "bedrock/claude-3-5-sonnet-20240620-v2": {
        "company": "Amazon",
        "label": "Claude 3.5 Sonnet (Bedrock)",
        "description": "Claude 3.5 Sonnet is a multimodal understanding foundation model. It is multilingual and can reason over text, images and videos.",
        "release_date": "2024-10-22",
        "open_source": false,
        "documentation_url": "https://docs.anthropic.com/en/docs/models/claude-3-5-sonnet",
        "properties": {
            "context_window": 100000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "bedrock",
        "provider_endpoint": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        "full_key": "bedrock/claude-3-5-sonnet-20240620-v2",
        "slug": "bedrock_claude-3-5-sonnet-20240620-v2"
    },
    "bedrock/claude-3-5-haiku-20241022-v1": {
        "company": "Amazon",
        "label": "Claude 3.5 Haiku (Bedrock)",
        "description": "Claude 3.5 Haiku, hosted on Bedrock.",
        "release_date": "2024-10-22",
        "open_source": false,
        "documentation_url": "https://docs.anthropic.com/en/docs/models/claude-3-5-sonnet",
        "properties": {
            "context_window": 200000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 4.0,
            "cache": {
                "read": 0.08,
                "write": 1.0,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "bedrock",
        "provider_endpoint": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
        "full_key": "bedrock/claude-3-5-haiku-20241022-v1",
        "slug": "bedrock_claude-3-5-haiku-20241022-v1"
    },
    "anthropic/claude-3.5-sonnet-latest": {
        "company": "Anthropic",
        "label": "Claude 3.5 Sonnet Latest",
        "description": "Claude Sonnet 3.5 is a deprecated model with high performance for coding and analysis tasks, supports multilingual and vision input.",
        "release_date": "2024-10-22",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 8192,
            "training_cutoff": "2024-04",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-5-sonnet-20241022",
        "full_key": "anthropic/claude-3.5-sonnet-latest",
        "slug": "anthropic_claude-3.5-sonnet-latest"
    },
    "anthropic/claude-3-5-sonnet-latest": {
        "company": "Anthropic",
        "label": "Claude 3.5 Sonnet Latest",
        "description": "Claude Sonnet 3.5 is a deprecated model with high performance for coding and analysis tasks, supports multilingual and vision input.",
        "release_date": "2024-10-22",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 8192,
            "training_cutoff": "2024-04",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-5-sonnet-20241022",
        "full_key": "anthropic/claude-3-5-sonnet-latest",
        "slug": "anthropic_claude-3-5-sonnet-latest"
    },
    "anthropic/claude-3-5-sonnet-20241022": {
        "company": "Anthropic",
        "label": "Claude 3.5 Sonnet Latest",
        "description": "Claude Sonnet 3.5 is a deprecated model with high performance for coding and analysis tasks, supports multilingual and vision input.",
        "release_date": "2024-10-22",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 8192,
            "training_cutoff": "2024-04",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "anthropic/claude-3-5-sonnet-latest",
            "anthropic/claude-3.5-sonnet-latest"
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-5-sonnet-20241022",
        "full_key": "anthropic/claude-3-5-sonnet-20241022",
        "slug": "anthropic_claude-3-5-sonnet-20241022"
    },
    "anthropic/claude-3-5-haiku-latest": {
        "company": "Anthropic",
        "label": "Claude 3.5 Haiku Latest",
        "description": "Claude Haiku 3.5 is the fastest model from Anthropic, optimized for instant responses and targeted tasks. Supports vision and text inputs.",
        "release_date": "2024-10-22",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 8192,
            "training_cutoff": "2024-07",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 4.0,
            "cache": {
                "read": 0.08,
                "write": 1.0,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-5-haiku-20241022",
        "full_key": "anthropic/claude-3-5-haiku-latest",
        "slug": "anthropic_claude-3-5-haiku-latest"
    },
    "anthropic/claude-3-5-haiku-20241022": {
        "company": "Anthropic",
        "label": "Claude 3.5 Haiku Latest",
        "description": "Claude Haiku 3.5 is the fastest model from Anthropic, optimized for instant responses and targeted tasks. Supports vision and text inputs.",
        "release_date": "2024-10-22",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 8192,
            "training_cutoff": "2024-07",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 4.0,
            "cache": {
                "read": 0.08,
                "write": 1.0,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "anthropic/claude-3-5-haiku-latest",
            "anthropic/claude-3-5-haiku"
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-5-haiku-20241022",
        "full_key": "anthropic/claude-3-5-haiku-20241022",
        "slug": "anthropic_claude-3-5-haiku-20241022"
    },
    "anthropic/claude-3-5-haiku": {
        "company": "Anthropic",
        "label": "Claude 3.5 Haiku Latest",
        "description": "Claude Haiku 3.5 is the fastest model from Anthropic, optimized for instant responses and targeted tasks. Supports vision and text inputs.",
        "release_date": "2024-10-22",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 8192,
            "training_cutoff": "2024-07",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 4.0,
            "cache": {
                "read": 0.08,
                "write": 1.0,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-5-haiku-20241022",
        "full_key": "anthropic/claude-3-5-haiku",
        "slug": "anthropic_claude-3-5-haiku"
    },
    "google/gemini-pro-1.5": {
        "company": "Google",
        "label": "Gemini 1.5 Pro (002)",
        "description": "Gemini 1.5 Pro is a high-performance model with multimodal capabilities useful for complex reasoning tasks and dataset analysis.",
        "release_date": "2024-09-24",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 2097152,
            "max_token_output": 8192,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 5.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-1.5-pro-002",
        "full_key": "google/gemini-pro-1.5",
        "slug": "google_gemini-pro-1.5"
    },
    "google/gemini-1.5-pro-latest": {
        "company": "Google",
        "label": "Gemini 1.5 Pro (002)",
        "description": "Gemini 1.5 Pro is a high-performance model with multimodal capabilities useful for complex reasoning tasks and dataset analysis.",
        "release_date": "2024-09-24",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 2097152,
            "max_token_output": 8192,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 5.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-1.5-pro-002",
        "full_key": "google/gemini-1.5-pro-latest",
        "slug": "google_gemini-1.5-pro-latest"
    },
    "google/gemini-1.5-pro-002": {
        "company": "Google",
        "label": "Gemini 1.5 Pro (002)",
        "description": "Gemini 1.5 Pro is a high-performance model with multimodal capabilities useful for complex reasoning tasks and dataset analysis.",
        "release_date": "2024-09-24",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 2097152,
            "max_token_output": 8192,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 5.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "google/gemini-1.5-pro-latest",
            "google/gemini-pro-1.5"
        ],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-1.5-pro-002",
        "full_key": "google/gemini-1.5-pro-002",
        "slug": "google_gemini-1.5-pro-002"
    },
    "google/gemini-1.5-flash-002": {
        "company": "Google",
        "label": "Gemini 1.5 Flash (002)",
        "description": "Gemini 1.5 Flash is an efficient and speedy version of Gemini 1.5 with support for multiple data types and large contexts.",
        "release_date": "2024-09-24",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 8192,
            "training_cutoff": "2024-05",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.075,
            "output": 0.3,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-1.5-flash-002",
        "full_key": "google/gemini-1.5-flash-002",
        "slug": "google_gemini-1.5-flash-002"
    },
    "mistralai/mistral-small-2402": {
        "company": "Mistral",
        "label": "Mistral Small (02/2024)",
        "description": "Latest version of the Mistral Small model.",
        "release_date": "2024-09-17",
        "open_source": false,
        "documentation_url": "https://docs.mistral.ai/getting-started/models/models_overview/",
        "properties": {
            "context_window": 32000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.6
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "mistralai",
        "provider_endpoint": "mistral-small-2402",
        "full_key": "mistralai/mistral-small-2402",
        "slug": "mistralai_mistral-small-2402"
    },
    "openai/o1-preview-2024-09-12": {
        "company": "OpenAI",
        "label": "o1 Preview",
        "description": "o1 Preview is a research preview of the o1-series reasoning model trained with reinforcement learning to perform complex reasoning.",
        "release_date": "2024-09-12",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o1-preview",
        "properties": {
            "context_window": 128000,
            "max_token_output": 32768,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 60.0,
            "cache": {
                "read": 7.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "openai/gpt-o1-preview"
        ],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o1-preview-2024-09-12",
        "full_key": "openai/o1-preview-2024-09-12",
        "slug": "openai_o1-preview-2024-09-12"
    },
    "openai/o1-preview": {
        "company": "OpenAI",
        "label": "o1 Preview",
        "description": "o1 Preview is a research preview of the o1 series reasoning model. Trained with reinforcement learning to perform complex reasoning and produce a long internal chain-of-thought before responding.",
        "release_date": "2024-09-12",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o1-preview",
        "properties": {
            "context_window": 128000,
            "max_token_output": 32768,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 60.0,
            "cache": {
                "read": 7.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o1-preview",
        "full_key": "openai/o1-preview",
        "slug": "openai_o1-preview"
    },
    "openai/o1-mini-2024-09-12": {
        "company": "OpenAI",
        "label": "o1 Mini",
        "description": "o1-mini is a small model alternative to o1 designed for high-reasoning tasks.",
        "release_date": "2024-09-12",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o1-mini",
        "properties": {
            "context_window": 128000,
            "max_token_output": 65536,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.1,
            "output": 4.4,
            "cache": {
                "read": 0.55,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "openai/o1-mini",
            "azure/o1-mini-2024-09-12"
        ],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o1-mini-2024-09-12",
        "full_key": "openai/o1-mini-2024-09-12",
        "slug": "openai_o1-mini-2024-09-12"
    },
    "openai/o1-mini": {
        "company": "OpenAI",
        "label": "o1 Mini",
        "description": "o1-mini is a small model alternative to o1 designed for high-reasoning tasks.",
        "release_date": "2024-09-12",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o1-mini",
        "properties": {
            "context_window": 128000,
            "max_token_output": 65536,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.1,
            "output": 4.4,
            "cache": {
                "read": 0.55,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o1-mini-2024-09-12",
        "full_key": "openai/o1-mini",
        "slug": "openai_o1-mini"
    },
    "openai/gpt-o1-preview": {
        "company": "OpenAI",
        "label": "o1 Preview",
        "description": "o1 Preview is a research preview of the o1-series reasoning model trained with reinforcement learning to perform complex reasoning.",
        "release_date": "2024-09-12",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o1-preview",
        "properties": {
            "context_window": 128000,
            "max_token_output": 32768,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 60.0,
            "cache": {
                "read": 7.5,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "o1-preview-2024-09-12",
        "full_key": "openai/gpt-o1-preview",
        "slug": "openai_gpt-o1-preview"
    },
    "azure/o1-mini-2024-09-12": {
        "company": "OpenAI",
        "label": "o1 Mini",
        "description": "o1-mini is a small model alternative to o1 designed for high-reasoning tasks.",
        "release_date": "2024-09-12",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/o1-mini",
        "properties": {
            "context_window": 128000,
            "max_token_output": 65536,
            "training_cutoff": "2023-10",
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": false,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.1,
            "output": 4.4,
            "cache": {
                "read": 0.55,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "o1-mini-2024-09-12",
        "full_key": "azure/o1-mini-2024-09-12",
        "slug": "azure_o1-mini-2024-09-12"
    },
    "cohere/command-r-plus-08-2024": {
        "company": "Cohere",
        "label": "Command R+ (08/2024)",
        "description": "Command R+ (August 2024) is designed for complex RAG workflows and multi-step tool use, supporting 128K context length.",
        "release_date": "2024-08-30",
        "open_source": false,
        "documentation_url": "https://docs.cohere.com/v2/docs/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4000,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.5,
            "output": 10.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "cohere",
        "provider_endpoint": "command-r-plus-08-2024",
        "full_key": "cohere/command-r-plus-08-2024",
        "slug": "cohere_command-r-plus-08-2024"
    },
    "cohere/command-r-08-2024": {
        "company": "Cohere",
        "label": "Command R (08/2024)",
        "description": "Command R (August 2024) is an updated instruction-following conversational model suitable for complex workflows including code generation, retrieval augmentations, and tool use, with 128K context.",
        "release_date": "2024-08-30",
        "open_source": false,
        "documentation_url": "https://docs.cohere.com/v2/docs/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4000,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "cohere",
        "provider_endpoint": "command-r-08-2024",
        "full_key": "cohere/command-r-08-2024",
        "slug": "cohere_command-r-08-2024"
    },
    "ai21labs/jamba-mini-1.5": {
        "company": "AI21 Labs",
        "label": "Jamba 1.5 Mini",
        "description": "Efficient & lightweight model for a wide range of tasks",
        "release_date": "2024-08-22",
        "open_source": true,
        "documentation_url": "https://www.ai21.com/jamba",
        "properties": {
            "context_window": 256000,
            "max_token_output": 4096,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.4
        },
        "alternative_keys": [
            "ai21labs/jamba-1.5-mini"
        ],
        "default_parameters": {
            "temperature": 0.4
        },
        "provider_name": "ai21labs",
        "provider_endpoint": "jamba-mini-1.5",
        "full_key": "ai21labs/jamba-mini-1.5",
        "slug": "ai21labs_jamba-mini-1.5"
    },
    "ai21labs/jamba-large-1.5": {
        "company": "AI21 Labs",
        "label": "Jamba 1.5 Large",
        "description": "The most powerful and efficient long context model",
        "release_date": "2024-08-22",
        "open_source": true,
        "documentation_url": "https://www.ai21.com/jamba",
        "properties": {
            "context_window": 256000,
            "max_token_output": 4096,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0
        },
        "alternative_keys": [
            "ai21labs/jamba-1.5-large"
        ],
        "default_parameters": {
            "temperature": 0.4
        },
        "provider_name": "ai21labs",
        "provider_endpoint": "jamba-large-1.5",
        "full_key": "ai21labs/jamba-large-1.5",
        "slug": "ai21labs_jamba-large-1.5"
    },
    "ai21labs/jamba-1.5-mini": {
        "company": "AI21 Labs",
        "label": "Jamba 1.5 Mini",
        "description": "Efficient & lightweight model for a wide range of tasks",
        "release_date": "2024-08-22",
        "open_source": true,
        "documentation_url": "https://www.ai21.com/jamba",
        "properties": {
            "context_window": 256000,
            "max_token_output": 4096,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.4
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.4
        },
        "provider_name": "ai21labs",
        "provider_endpoint": "jamba-mini-1.5",
        "full_key": "ai21labs/jamba-1.5-mini",
        "slug": "ai21labs_jamba-1.5-mini"
    },
    "ai21labs/jamba-1.5-large": {
        "company": "AI21 Labs",
        "label": "Jamba 1.5 Large",
        "description": "The most powerful and efficient long context model",
        "release_date": "2024-08-22",
        "open_source": true,
        "documentation_url": "https://www.ai21.com/jamba",
        "properties": {
            "context_window": 256000,
            "max_token_output": 4096,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.4
        },
        "provider_name": "ai21labs",
        "provider_endpoint": "jamba-large-1.5",
        "full_key": "ai21labs/jamba-1.5-large",
        "slug": "ai21labs_jamba-1.5-large"
    },
    "openai/gpt-4o-2024-08-06": {
        "company": "OpenAI",
        "label": "GPT 4o (2024-08-06)",
        "description": "GPT-4o is a fast, intelligent, flexible GPT model that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-08-06",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4o",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": "2023-10",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.5,
            "output": 10.0,
            "cache": {
                "read": 1.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4o-2024-08-06",
        "full_key": "openai/gpt-4o-2024-08-06",
        "slug": "openai_gpt-4o-2024-08-06"
    },
    "openai/gpt-4o": {
        "company": "OpenAI",
        "label": "GPT 4o",
        "description": "GPT-4o is a fast, intelligent, flexible GPT model that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-08-06",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4o",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": "2023-10",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.5,
            "output": 10.0,
            "cache": {
                "read": 1.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4o",
        "full_key": "openai/gpt-4o",
        "slug": "openai_gpt-4o"
    },
    "together/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
        "company": "Meta",
        "label": "Llama 3.1 Instruct Turbo (8B)",
        "description": "Llama 3.1 Instruct Turbo, 8B parameters with FP8 quantization.",
        "release_date": "2024-07-23",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [
            "together/llama-3.1-8b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "full_key": "together/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "slug": "together_meta-llama_Meta-Llama-3.1-8B-Instruct-Turbo"
    },
    "together/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
        "company": "Meta",
        "label": "Llama 3.1 Instruct Turbo (70B)",
        "description": "Llama 3.1 Instruct Turbo, 70B parameters with FP8 quantization.",
        "release_date": "2024-07-23",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.88,
            "output": 0.88
        },
        "alternative_keys": [
            "together/llama-3.1-70b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "full_key": "together/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "slug": "together_meta-llama_Meta-Llama-3.1-70B-Instruct-Turbo"
    },
    "together/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
        "company": "Meta",
        "label": "Llama 3.1 Instruct Turbo (405B)",
        "description": "Llama 3.1 Instruct Turbo, 405B parameters with FP8 quantization and reduced context.",
        "release_date": "2024-07-23",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 130815,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.5,
            "output": 3.5
        },
        "alternative_keys": [
            "together/llama-3.1-405b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
        "full_key": "together/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
        "slug": "together_meta-llama_Meta-Llama-3.1-405B-Instruct-Turbo"
    },
    "together/llama-3.1-8b-instruct": {
        "company": "Meta",
        "label": "Llama 3.1 Instruct Turbo (8B)",
        "description": "Llama 3.1 Instruct Turbo, 8B parameters with FP8 quantization.",
        "release_date": "2024-07-23",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "full_key": "together/llama-3.1-8b-instruct",
        "slug": "together_llama-3.1-8b-instruct"
    },
    "together/llama-3.1-70b-instruct": {
        "company": "Meta",
        "label": "Llama 3.1 Instruct Turbo (70B)",
        "description": "Llama 3.1 Instruct Turbo, 70B parameters with FP8 quantization.",
        "release_date": "2024-07-23",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.88,
            "output": 0.88
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "full_key": "together/llama-3.1-70b-instruct",
        "slug": "together_llama-3.1-70b-instruct"
    },
    "together/llama-3.1-405b-instruct": {
        "company": "Meta",
        "label": "Llama 3.1 Instruct Turbo (405B)",
        "description": "Llama 3.1 Instruct Turbo, 405B parameters with FP8 quantization and reduced context.",
        "release_date": "2024-07-23",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 130815,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.5,
            "output": 3.5
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
        "full_key": "together/llama-3.1-405b-instruct",
        "slug": "together_llama-3.1-405b-instruct"
    },
    "openai/gpt-4o-mini-2024-07-18": {
        "company": "OpenAI",
        "label": "GPT 4o Mini",
        "description": "GPT-4o mini is a fast, affordable small model for focused tasks that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-07-18",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4o-mini",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": "2023-10",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6,
            "cache": {
                "read": 0.075,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/gpt-4o-mini-2024-07-18"
        ],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4o-mini-2024-07-18",
        "full_key": "openai/gpt-4o-mini-2024-07-18",
        "slug": "openai_gpt-4o-mini-2024-07-18"
    },
    "openai/gpt-4o-mini": {
        "company": "OpenAI",
        "label": "GPT 4o Mini",
        "description": "GPT-4o mini is a fast, affordable small model for focused tasks that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-07-18",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4o-mini",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": "2023-10",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6,
            "cache": {
                "read": 0.075,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4o-mini",
        "full_key": "openai/gpt-4o-mini",
        "slug": "openai_gpt-4o-mini"
    },
    "azure/gpt-4o-mini-2024-07-18": {
        "company": "OpenAI",
        "label": "GPT 4o Mini",
        "description": "GPT-4o mini is a fast, affordable small model for focused tasks that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-07-18",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4o-mini",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": "2023-10",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6,
            "cache": {
                "read": 0.075,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "gpt-4o-mini-2024-07-18",
        "full_key": "azure/gpt-4o-mini-2024-07-18",
        "slug": "azure_gpt-4o-mini-2024-07-18"
    },
    "anthropic/claude-3.5-sonnet": {
        "company": "Anthropic",
        "label": "Claude 3.5 Sonnet",
        "description": "Claude Sonnet 3.5 (June 2024) variant for code and content generation, multilingual and vision-capable, deprecated.",
        "release_date": "2024-06-20",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 8192,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-5-sonnet-20240620",
        "full_key": "anthropic/claude-3.5-sonnet",
        "slug": "anthropic_claude-3.5-sonnet"
    },
    "anthropic/claude-3-5-sonnet-20240620": {
        "company": "Anthropic",
        "label": "Claude 3.5 Sonnet",
        "description": "Claude Sonnet 3.5 (June 2024) variant for code and content generation, multilingual and vision-capable, deprecated.",
        "release_date": "2024-06-20",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 8192,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "anthropic/claude-3.5-sonnet"
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-5-sonnet-20240620",
        "full_key": "anthropic/claude-3-5-sonnet-20240620",
        "slug": "anthropic_claude-3-5-sonnet-20240620"
    },
    "google/gemini-1.5-pro-001": {
        "company": "Google",
        "label": "Gemini 1.5 Pro (001)",
        "description": "Gemini 1.5 Pro (early release) supports multimodal inputs and advanced reasoning on moderate context lengths.",
        "release_date": "2024-05-24",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 8192,
            "training_cutoff": "2023-11",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.25,
            "output": 5.0,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-1.5-pro-001",
        "full_key": "google/gemini-1.5-pro-001",
        "slug": "google_gemini-1.5-pro-001"
    },
    "google/gemini-1.5-flash-001": {
        "company": "Google",
        "label": "Gemini 1.5 Flash (001)",
        "description": "Gemini 1.5 Flash (early release) provides fast processing with vision and audio capabilities along with text understanding.",
        "release_date": "2024-05-24",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 1048576,
            "max_token_output": 8192,
            "training_cutoff": "2023-11",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_videos": true,
            "supports_files": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.075,
            "output": 0.3,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-1.5-flash-001",
        "full_key": "google/gemini-1.5-flash-001",
        "slug": "google_gemini-1.5-flash-001"
    },
    "openai/gpt-4o-2024-05-13": {
        "company": "OpenAI",
        "label": "GPT 4o (2024-05-13)",
        "description": "GPT-4o is a fast, intelligent, flexible GPT model that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-05-13",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4o",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": "2023-10",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": false,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 5.0,
            "output": 15.0,
            "cache": {
                "read_discount": 1.0,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4o-2024-05-13",
        "full_key": "openai/gpt-4o-2024-05-13",
        "slug": "openai_gpt-4o-2024-05-13"
    },
    "cohere/command-r-plus-04-2024": {
        "company": "Cohere",
        "label": "Command R+ (04/2024)",
        "description": "Command R+ (April 2024) supports high-quality language tasks with reliable performance over long contexts (128K tokens), optimized for complex reasoning and multi-step tool use.",
        "release_date": "2024-04-24",
        "open_source": false,
        "documentation_url": "https://docs.cohere.com/v2/docs/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4000,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.5,
            "output": 10.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "cohere",
        "provider_endpoint": "command-r-plus-04-2024",
        "full_key": "cohere/command-r-plus-04-2024",
        "slug": "cohere_command-r-plus-04-2024"
    },
    "cohere/command-r-plus": {
        "company": "Cohere",
        "label": "Command R+",
        "description": "Alias for Command R+ 04-2024, featuring high-quality instruction following, long context support, and optimized for complex reasoning and retrieval augmented generation.",
        "release_date": "2024-04-24",
        "open_source": false,
        "documentation_url": "https://docs.cohere.com/v2/docs/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4000,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.5,
            "output": 10.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "cohere",
        "provider_endpoint": "command-r-plus",
        "full_key": "cohere/command-r-plus",
        "slug": "cohere_command-r-plus"
    },
    "cohere/command-r": {
        "company": "Cohere",
        "label": "Command R",
        "description": "Alias for Command R 03-2024, an instruction-following conversational model focused on reliability and extended context for complex workflows.",
        "release_date": "2024-04-24",
        "open_source": false,
        "documentation_url": "https://docs.cohere.com/v2/docs/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4000,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "cohere",
        "provider_endpoint": "command-r",
        "full_key": "cohere/command-r",
        "slug": "cohere_command-r"
    },
    "cohere/command-light": {
        "company": "Cohere",
        "label": "Command Light",
        "description": "A smaller, faster version of the Command model that remains highly capable but optimized for speed with a shorter 4K context length.",
        "release_date": "2024-04-24",
        "open_source": false,
        "documentation_url": "https://docs.cohere.com/v2/docs/models",
        "properties": {
            "context_window": 4000,
            "max_token_output": 4000,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.6
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "cohere",
        "provider_endpoint": "command-light",
        "full_key": "cohere/command-light",
        "slug": "cohere_command-light"
    },
    "together/qwen-2.5-7b-instruct": {
        "company": "Alibaba",
        "label": "Qwen 2.5 Instruct Turbo (7B)",
        "description": "Qwen 2.5 Instruct Turbo, 7B parameters with FP8 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.3
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "together",
        "provider_endpoint": "Qwen/Qwen2.5-7B-Instruct-Turbo",
        "full_key": "together/qwen-2.5-7b-instruct",
        "slug": "together_qwen-2.5-7b-instruct"
    },
    "together/qwen-2.5-72b-instruct": {
        "company": "Alibaba",
        "label": "Qwen 2.5 Instruct Turbo (72B)",
        "description": "Qwen 2.5 Instruct Turbo, 72B parameters with FP8 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 1.2
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "together",
        "provider_endpoint": "Qwen/Qwen2.5-72B-Instruct-Turbo",
        "full_key": "together/qwen-2.5-72b-instruct",
        "slug": "together_qwen-2.5-72b-instruct"
    },
    "together/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF": {
        "company": "NVIDIA",
        "label": "Llama 3.1 Nemotron (70B)",
        "description": "Nvidia's 70B Nemotron model, fine-tuned with Llama 3.1 weights.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
        "full_key": "together/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
        "slug": "together_nvidia_Llama-3.1-Nemotron-70B-Instruct-HF"
    },
    "together/mistralai/Mistral-7B-Instruct-v0.3": {
        "company": "Mistral",
        "label": "Mistral Instruct (7B) v0.3",
        "description": "Latest third version of Mistral 7B Instruct model.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [
            "together/Mistral-7B-Instruct-v0.3"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mistral-7B-Instruct-v0.3",
        "full_key": "together/mistralai/Mistral-7B-Instruct-v0.3",
        "slug": "together_mistralai_Mistral-7B-Instruct-v0.3"
    },
    "together/meta-llama/Meta-Llama-3-8B-Instruct-Turbo": {
        "company": "Meta",
        "label": "Llama 3 Instruct Turbo (8B)",
        "description": "Llama 3 Instruct Turbo, 8B parameters with FP8 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [
            "together/llama-3-8b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3-8B-Instruct-Turbo",
        "full_key": "together/meta-llama/Meta-Llama-3-8B-Instruct-Turbo",
        "slug": "together_meta-llama_Meta-Llama-3-8B-Instruct-Turbo"
    },
    "together/meta-llama/Meta-Llama-3-8B-Instruct-Lite": {
        "company": "Meta",
        "label": "Llama 3 Instruct Lite (8B)",
        "description": "Llama 3 Instruct Lite, 8B parameters with INT4 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.1
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3-8B-Instruct-Lite",
        "full_key": "together/meta-llama/Meta-Llama-3-8B-Instruct-Lite",
        "slug": "together_meta-llama_Meta-Llama-3-8B-Instruct-Lite"
    },
    "together/meta-llama/Meta-Llama-3-70B-Instruct-Turbo": {
        "company": "Meta",
        "label": "Llama 3 Instruct Turbo (70B)",
        "description": "Llama 3 Instruct Turbo, 70B parameters with FP8 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.88,
            "output": 0.88
        },
        "alternative_keys": [
            "together/llama-3-70b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
        "full_key": "together/meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
        "slug": "together_meta-llama_Meta-Llama-3-70B-Instruct-Turbo"
    },
    "together/meta-llama/Meta-Llama-3-70B-Instruct-Lite": {
        "company": "Meta",
        "label": "Llama 3 Instruct Lite (70B)",
        "description": "Llama 3 Instruct Lite, 70B parameters with INT4 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.54,
            "output": 0.54
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3-70B-Instruct-Lite",
        "full_key": "together/meta-llama/Meta-Llama-3-70B-Instruct-Lite",
        "slug": "together_meta-llama_Meta-Llama-3-70B-Instruct-Lite"
    },
    "together/meta-llama/Llama-Vision-Free": {
        "company": "Meta",
        "label": "Llama Vision Free",
        "description": "Free version of Llama Vision 11B Turbo with reduced rate limits.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {},
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-Vision-Free",
        "full_key": "together/meta-llama/Llama-Vision-Free",
        "slug": "together_meta-llama_Llama-Vision-Free"
    },
    "together/meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
        "company": "Meta",
        "label": "Llama 3.2 Vision (90B)",
        "description": "Vision-enabled Llama model with 90B parameters for advanced use cases.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 1.2
        },
        "alternative_keys": [
            "together/llama-3.2-90b-vision-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
        "full_key": "together/meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
        "slug": "together_meta-llama_Llama-3.2-90B-Vision-Instruct-Turbo"
    },
    "together/meta-llama/Llama-3.2-3B-Instruct-Turbo": {
        "company": "Meta",
        "label": "Llama 3.2 Instruct Turbo (3B)",
        "description": "Llama 3.2 Instruct Turbo, 3B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.06,
            "output": 0.06
        },
        "alternative_keys": [
            "together/llama-3.2-3b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
        "full_key": "together/meta-llama/Llama-3.2-3B-Instruct-Turbo",
        "slug": "together_meta-llama_Llama-3.2-3B-Instruct-Turbo"
    },
    "together/meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
        "company": "Meta",
        "label": "Llama 3.2 Vision (11B)",
        "description": "Paid version of Llama Vision 11B Turbo for high-performance visual tasks.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [
            "together/llama-3.2-11b-vision-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
        "full_key": "together/meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
        "slug": "together_meta-llama_Llama-3.2-11B-Vision-Instruct-Turbo"
    },
    "together/meta-llama/Llama-3-8b-hf": {
        "company": "Meta",
        "label": "Llama 3 (8B)",
        "description": "Llama 3 Reference Model, 8B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [
            "together/llama-3-8b"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3-8b-hf",
        "full_key": "together/meta-llama/Llama-3-8b-hf",
        "slug": "together_meta-llama_Llama-3-8b-hf"
    },
    "together/meta-llama/Llama-3-8b-chat-hf": {
        "company": "Meta",
        "label": "Llama 3 Chat (8B)",
        "description": "Llama 3 Reference Model, 8B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [
            "together/llama-3-8b-chat"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3-8b-chat-hf",
        "full_key": "together/meta-llama/Llama-3-8b-chat-hf",
        "slug": "together_meta-llama_Llama-3-8b-chat-hf"
    },
    "together/meta-llama/Llama-3-70b-chat-hf": {
        "company": "Meta",
        "label": "Llama 3 Chat (70B)",
        "description": "Llama 3 Reference Model, 70B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9
        },
        "alternative_keys": [
            "together/llama-3-70b-chat"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3-70b-chat-hf",
        "full_key": "together/meta-llama/Llama-3-70b-chat-hf",
        "slug": "together_meta-llama_Llama-3-70b-chat-hf"
    },
    "together/meta-llama/Llama-3-70B": {
        "company": "Meta",
        "label": "Llama 3 (70B)",
        "description": "Llama 3 Reference Model, 70B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9
        },
        "alternative_keys": [
            "together/llama-3-70b"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3-70B",
        "full_key": "together/meta-llama/Llama-3-70B",
        "slug": "together_meta-llama_Llama-3-70B"
    },
    "together/llama-3.2-90b-vision-instruct": {
        "company": "Meta",
        "label": "Llama 3.2 Vision (90B)",
        "description": "Vision-enabled Llama model with 90B parameters for advanced use cases.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 1.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
        "full_key": "together/llama-3.2-90b-vision-instruct",
        "slug": "together_llama-3.2-90b-vision-instruct"
    },
    "together/llama-3.2-90b-instruct": {
        "company": "Meta",
        "label": "Llama 3.2 Instruct Turbo (90B)",
        "description": "Llama 3.2 Instruct Turbo, 90B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 1.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
        "full_key": "together/llama-3.2-90b-instruct",
        "slug": "together_llama-3.2-90b-instruct"
    },
    "together/llama-3.2-3b-instruct": {
        "company": "Meta",
        "label": "Llama 3.2 Instruct Turbo (3B)",
        "description": "Llama 3.2 Instruct Turbo, 3B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.06,
            "output": 0.06
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
        "full_key": "together/llama-3.2-3b-instruct",
        "slug": "together_llama-3.2-3b-instruct"
    },
    "together/llama-3.2-11b-vision-instruct": {
        "company": "Meta",
        "label": "Llama 3.2 Vision (11B)",
        "description": "Paid version of Llama Vision 11B Turbo for high-performance visual tasks.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
        "full_key": "together/llama-3.2-11b-vision-instruct",
        "slug": "together_llama-3.2-11b-vision-instruct"
    },
    "together/llama-3.2-11b-instruct": {
        "company": "Meta",
        "label": "Llama 3.2 Instruct Turbo (11B)",
        "description": "Llama 3.2 Instruct Turbo, 11B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 131072,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
        "full_key": "together/llama-3.2-11b-instruct",
        "slug": "together_llama-3.2-11b-instruct"
    },
    "together/llama-3-8b-instruct": {
        "company": "Meta",
        "label": "Llama 3 Instruct Turbo (8B)",
        "description": "Llama 3 Instruct Turbo, 8B parameters with FP8 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3-8B-Instruct-Turbo",
        "full_key": "together/llama-3-8b-instruct",
        "slug": "together_llama-3-8b-instruct"
    },
    "together/llama-3-8b-chat": {
        "company": "Meta",
        "label": "Llama 3 Chat (8B)",
        "description": "Llama 3 Reference Model, 8B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3-8b-chat-hf",
        "full_key": "together/llama-3-8b-chat",
        "slug": "together_llama-3-8b-chat"
    },
    "together/llama-3-8b": {
        "company": "Meta",
        "label": "Llama 3 (8B)",
        "description": "Llama 3 Reference Model, 8B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-03",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3-8b-hf",
        "full_key": "together/llama-3-8b",
        "slug": "together_llama-3-8b"
    },
    "together/llama-3-70b-instruct": {
        "company": "Meta",
        "label": "Llama 3 Instruct Turbo (70B)",
        "description": "Llama 3 Instruct Turbo, 70B parameters with FP8 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.88,
            "output": 0.88
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
        "full_key": "together/llama-3-70b-instruct",
        "slug": "together_llama-3-70b-instruct"
    },
    "together/llama-3-70b-chat": {
        "company": "Meta",
        "label": "Llama 3 Chat (70B)",
        "description": "Llama 3 Reference Model, 70B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3-70b-chat-hf",
        "full_key": "together/llama-3-70b-chat",
        "slug": "together_llama-3-70b-chat"
    },
    "together/llama-3-70b": {
        "company": "Meta",
        "label": "Llama 3 (70B)",
        "description": "Llama 3 Reference Model, 70B parameters with FP16 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-3-70B",
        "full_key": "together/llama-3-70b",
        "slug": "together_llama-3-70b"
    },
    "together/Qwen/Qwen2.5-Coder-32B-Instruct": {
        "company": "Alibaba",
        "label": "Qwen 2.5 Coder (32B)",
        "description": "Qwen Coder 2.5, 32B parameters fine-tuned for coding tasks.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 0.8
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "together",
        "provider_endpoint": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "full_key": "together/Qwen/Qwen2.5-Coder-32B-Instruct",
        "slug": "together_Qwen_Qwen2.5-Coder-32B-Instruct"
    },
    "together/Qwen/Qwen2.5-7B-Instruct-Turbo": {
        "company": "Alibaba",
        "label": "Qwen 2.5 Instruct Turbo (7B)",
        "description": "Qwen 2.5 Instruct Turbo, 7B parameters with FP8 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.3
        },
        "alternative_keys": [
            "together/qwen-2.5-7b-instruct"
        ],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "together",
        "provider_endpoint": "Qwen/Qwen2.5-7B-Instruct-Turbo",
        "full_key": "together/Qwen/Qwen2.5-7B-Instruct-Turbo",
        "slug": "together_Qwen_Qwen2.5-7B-Instruct-Turbo"
    },
    "together/Qwen/Qwen2.5-72B-Instruct-Turbo": {
        "company": "Alibaba",
        "label": "Qwen 2.5 Instruct Turbo (72B)",
        "description": "Qwen 2.5 Instruct Turbo, 72B parameters with FP8 quantization.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 1.2
        },
        "alternative_keys": [
            "together/qwen-2.5-72b-instruct"
        ],
        "default_parameters": {
            "temperature": 0.7
        },
        "provider_name": "together",
        "provider_endpoint": "Qwen/Qwen2.5-72B-Instruct-Turbo",
        "full_key": "together/Qwen/Qwen2.5-72B-Instruct-Turbo",
        "slug": "together_Qwen_Qwen2.5-72B-Instruct-Turbo"
    },
    "together/Mistral-7B-Instruct-v0.3": {
        "company": "Mistral",
        "label": "Mistral Instruct (7B) v0.3",
        "description": "Latest third version of Mistral 7B Instruct model.",
        "release_date": "2024-04-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mistral-7B-Instruct-v0.3",
        "full_key": "together/Mistral-7B-Instruct-v0.3",
        "slug": "together_Mistral-7B-Instruct-v0.3"
    },
    "openai/gpt-4-turbo-2024-04-09": {
        "company": "OpenAI",
        "label": "GPT 4 Turbo (2024-04-09)",
        "description": "GPT-4 Turbo is an older high-intelligence GPT model that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-04-09",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4-turbo",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 10.0,
            "output": 30.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "azure/gpt-4-turbo-2024-04-09"
        ],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4-turbo-2024-04-09",
        "full_key": "openai/gpt-4-turbo-2024-04-09",
        "slug": "openai_gpt-4-turbo-2024-04-09"
    },
    "openai/gpt-4-turbo": {
        "company": "OpenAI",
        "label": "GPT 4 Turbo",
        "description": "GPT-4 Turbo is an older high-intelligence GPT model that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-04-09",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4-turbo",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 10.0,
            "output": 30.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "openai/gpt-4"
        ],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4-turbo",
        "full_key": "openai/gpt-4-turbo",
        "slug": "openai_gpt-4-turbo"
    },
    "azure/gpt-4-turbo-2024-04-09": {
        "company": "OpenAI",
        "label": "GPT 4 Turbo (2024-04-09)",
        "description": "GPT-4 Turbo is an older high-intelligence GPT model that accepts text and image inputs and produces text outputs.",
        "release_date": "2024-04-09",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4-turbo",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 10.0,
            "output": 30.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "azure",
        "provider_endpoint": "gpt-4-turbo-2024-04-09",
        "full_key": "azure/gpt-4-turbo-2024-04-09",
        "slug": "azure_gpt-4-turbo-2024-04-09"
    },
    "databricks/dbrx-instruct": {
        "company": "Databricks",
        "label": "DBRX Instruct",
        "description": "Databricks Instruct model.",
        "release_date": "2024-03-27",
        "open_source": false,
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.25,
            "output": 6.75,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "databricks",
        "provider_endpoint": "databricks-dbrx-instruct",
        "full_key": "databricks/dbrx-instruct",
        "slug": "databricks_dbrx-instruct"
    },
    "databricks/databricks-dbrx-instruct": {
        "company": "Databricks",
        "label": "DBRX Instruct",
        "description": "Databricks Instruct model.",
        "release_date": "2024-03-27",
        "open_source": false,
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.25,
            "output": 6.75,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "databricks/dbrx-instruct"
        ],
        "default_parameters": {
            "reasoning_effort": "high"
        },
        "provider_name": "databricks",
        "provider_endpoint": "databricks-dbrx-instruct",
        "full_key": "databricks/databricks-dbrx-instruct",
        "slug": "databricks_databricks-dbrx-instruct"
    },
    "cohere/command-r-03-2024": {
        "company": "Cohere",
        "label": "Command R (03/2024)",
        "description": "Command R 03-2024 is an instruction-following conversational model with improved quality, longer context (128K tokens), suitable for code generation, RAG, and complex workflows.",
        "release_date": "2024-03-24",
        "open_source": false,
        "documentation_url": "https://docs.cohere.com/v2/docs/models",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4000,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "cohere",
        "provider_endpoint": "command-r-03-2024",
        "full_key": "cohere/command-r-03-2024",
        "slug": "cohere_command-r-03-2024"
    },
    "cohere/command": {
        "company": "Cohere",
        "label": "Command",
        "description": "Command is the base instruction-following conversational model delivering high-quality language task performance, with a context of 4K tokens.",
        "release_date": "2024-03-24",
        "open_source": false,
        "documentation_url": "https://docs.cohere.com/v2/docs/models",
        "properties": {
            "context_window": 4000,
            "max_token_output": 4000,
            "training_cutoff": null
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.0,
            "output": 2.0
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 0.3
        },
        "provider_name": "cohere",
        "provider_endpoint": "command",
        "full_key": "cohere/command",
        "slug": "cohere_command"
    },
    "anthropic/claude-3-sonnet-20240229": {
        "company": "Anthropic",
        "label": "Claude 3 Sonnet",
        "description": "Claude Sonnet 3 is a high-performance language model supporting text and image input, with balanced skill for complex NLP tasks.",
        "release_date": "2024-02-29",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 4096,
            "training_cutoff": "2023-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "anthropic/claude-3-sonnet"
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-sonnet-20240229",
        "full_key": "anthropic/claude-3-sonnet-20240229",
        "slug": "anthropic_claude-3-sonnet-20240229"
    },
    "anthropic/claude-3-sonnet": {
        "company": "Anthropic",
        "label": "Claude 3 Sonnet",
        "description": "Claude Sonnet 3 is a high-performance language model supporting text and image input, with balanced skill for complex NLP tasks.",
        "release_date": "2024-02-29",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 4096,
            "training_cutoff": "2023-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-sonnet-20240229",
        "full_key": "anthropic/claude-3-sonnet",
        "slug": "anthropic_claude-3-sonnet"
    },
    "anthropic/claude-3-opus-latest": {
        "company": "Anthropic",
        "label": "Claude 3 Opus",
        "description": "Claude Opus 3 was Anthropic's most capable model for advanced tasks in its generation, supporting multimodal input.",
        "release_date": "2024-02-29",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 4096,
            "training_cutoff": "2023-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0,
            "cache": {
                "read": 1.5,
                "write": 18.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-opus-20240229",
        "full_key": "anthropic/claude-3-opus-latest",
        "slug": "anthropic_claude-3-opus-latest"
    },
    "anthropic/claude-3-opus-20240229": {
        "company": "Anthropic",
        "label": "Claude 3 Opus",
        "description": "Claude Opus 3 was Anthropic's most capable model for advanced tasks in its generation, supporting multimodal input.",
        "release_date": "2024-02-29",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 4096,
            "training_cutoff": "2023-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0,
            "cache": {
                "read": 1.5,
                "write": 18.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "anthropic/claude-3-opus-latest",
            "anthropic/claude-3-opus"
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-opus-20240229",
        "full_key": "anthropic/claude-3-opus-20240229",
        "slug": "anthropic_claude-3-opus-20240229"
    },
    "anthropic/claude-3-opus": {
        "company": "Anthropic",
        "label": "Claude 3 Opus",
        "description": "Claude Opus 3 was Anthropic's most capable model for advanced tasks in its generation, supporting multimodal input.",
        "release_date": "2024-02-29",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 4096,
            "training_cutoff": "2023-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 15.0,
            "output": 75.0,
            "cache": {
                "read": 1.5,
                "write": 18.75,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-opus-20240229",
        "full_key": "anthropic/claude-3-opus",
        "slug": "anthropic_claude-3-opus"
    },
    "anthropic/claude-3-haiku-20240307": {
        "company": "Anthropic",
        "label": "Claude 3 Sonnet",
        "description": "Claude Haiku 3 is a compact, fast model optimized for near-instant responsiveness and targeted queries with text/image input.",
        "release_date": "2024-02-29",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 4096,
            "training_cutoff": "2023-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.25,
            "output": 1.25,
            "cache": {
                "read": 0.03,
                "write": 0.3,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "anthropic/claude-3-haiku"
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-haiku-20240307",
        "full_key": "anthropic/claude-3-haiku-20240307",
        "slug": "anthropic_claude-3-haiku-20240307"
    },
    "anthropic/claude-3-haiku": {
        "company": "Anthropic",
        "label": "Claude 3 Sonnet",
        "description": "Claude Haiku 3 is a compact, fast model optimized for near-instant responsiveness and targeted queries with text/image input.",
        "release_date": "2024-02-29",
        "open_source": false,
        "documentation_url": "https://docs.claude.com/en/docs/about-claude/models/overview",
        "properties": {
            "context_window": 200000,
            "max_token_output": 4096,
            "training_cutoff": "2023-08",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.25,
            "output": 1.25,
            "cache": {
                "read": 0.03,
                "write": 0.3,
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-3-haiku-20240307",
        "full_key": "anthropic/claude-3-haiku",
        "slug": "anthropic_claude-3-haiku"
    },
    "together/google/gemma-2-9b-it": {
        "company": "Google",
        "label": "Gemma 2 (9B)",
        "description": "Gemini 9B Instruct Turbo model.",
        "release_date": "2024-02-21",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [
            "together/gemma-2-9b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "google/gemma-2-9b-it",
        "full_key": "together/google/gemma-2-9b-it",
        "slug": "together_google_gemma-2-9b-it"
    },
    "together/google/gemma-2-2b-it": {
        "company": "Google",
        "label": "Gemma 2 (2B)",
        "description": "Gemini 2B Instruct Turbo model.",
        "release_date": "2024-02-21",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.1
        },
        "alternative_keys": [
            "together/gemma-2-2b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "google/gemma-2-2b-it",
        "full_key": "together/google/gemma-2-2b-it",
        "slug": "together_google_gemma-2-2b-it"
    },
    "together/google/gemma-2-27b-it": {
        "company": "Google",
        "label": "Gemma 2 (27B)",
        "description": "Gemini 27B Instruct Turbo model.",
        "release_date": "2024-02-21",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 0.5
        },
        "alternative_keys": [
            "together/gemma-2-27b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "google/gemma-2-27b-it",
        "full_key": "together/google/gemma-2-27b-it",
        "slug": "together_google_gemma-2-27b-it"
    },
    "together/gemma-2-9b-instruct": {
        "company": "Google",
        "label": "Gemma 2 (9B)",
        "description": "Gemini 9B Instruct Turbo model.",
        "release_date": "2024-02-21",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "google/gemma-2-9b-it",
        "full_key": "together/gemma-2-9b-instruct",
        "slug": "together_gemma-2-9b-instruct"
    },
    "together/gemma-2-2b-instruct": {
        "company": "Google",
        "label": "Gemma 2 (2B)",
        "description": "Gemini 2B Instruct Turbo model.",
        "release_date": "2024-02-21",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.1,
            "output": 0.1
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "google/gemma-2-2b-it",
        "full_key": "together/gemma-2-2b-instruct",
        "slug": "together_gemma-2-2b-instruct"
    },
    "together/gemma-2-27b-instruct": {
        "company": "Google",
        "label": "Gemma 2 (27B)",
        "description": "Gemini 27B Instruct Turbo model.",
        "release_date": "2024-02-21",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 0.5
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "google/gemma-2-27b-it",
        "full_key": "together/gemma-2-27b-instruct",
        "slug": "together_gemma-2-27b-instruct"
    },
    "together/mistralai/Mixtral-8x22B-Instruct-v0.1": {
        "company": "Mistral",
        "label": "Mixtral Instruct (8x22B)",
        "description": "Mixtral model with 8x22B modules for large-scale inference.",
        "release_date": "2024-02-15",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 65536,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 1.2
        },
        "alternative_keys": [
            "together/Mixtral-8x22B-Instruct-v0.1",
            "together/Mixtral-8x22B-v0.1"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mixtral-8x22B-Instruct-v0.1",
        "full_key": "together/mistralai/Mixtral-8x22B-Instruct-v0.1",
        "slug": "together_mistralai_Mixtral-8x22B-Instruct-v0.1"
    },
    "together/Mixtral-8x22B-v0.1": {
        "company": "Mistral",
        "label": "Mixtral Instruct (8x22B)",
        "description": "Mixtral model with 8x22B modules for large-scale inference.",
        "release_date": "2024-02-15",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 65536,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 1.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mixtral-8x22B-Instruct-v0.1",
        "full_key": "together/Mixtral-8x22B-v0.1",
        "slug": "together_Mixtral-8x22B-v0.1"
    },
    "together/Mixtral-8x22B-Instruct-v0.1": {
        "company": "Mistral",
        "label": "Mixtral Instruct (8x22B)",
        "description": "Mixtral model with 8x22B modules for large-scale inference.",
        "release_date": "2024-02-15",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 65536,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.2,
            "output": 1.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mixtral-8x22B-Instruct-v0.1",
        "full_key": "together/Mixtral-8x22B-Instruct-v0.1",
        "slug": "together_Mixtral-8x22B-Instruct-v0.1"
    },
    "google/gemini-pro-1.0": {
        "company": "Google",
        "label": "Gemini 1.0 Pro 002",
        "description": "Gemini 1.0 Pro is an earlier generation multimodal model supporting text, image, and audio inputs with foundational reasoning abilities.",
        "release_date": "2024-02-14",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 32760,
            "max_token_output": 8192,
            "training_cutoff": "2023-02",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 1.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-1.0-pro-002",
        "full_key": "google/gemini-pro-1.0",
        "slug": "google_gemini-pro-1.0"
    },
    "google/gemini-pro": {
        "company": "Google",
        "label": "Gemini 1.0 Pro 002",
        "description": "Gemini 1.0 Pro is an earlier generation multimodal model supporting text, image, and audio inputs with foundational reasoning abilities.",
        "release_date": "2024-02-14",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 32760,
            "max_token_output": 8192,
            "training_cutoff": "2023-02",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 1.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-1.0-pro-002",
        "full_key": "google/gemini-pro",
        "slug": "google_gemini-pro"
    },
    "google/gemini-1.0-pro-002": {
        "company": "Google",
        "label": "Gemini 1.0 Pro 002",
        "description": "Gemini 1.0 Pro is an earlier generation multimodal model supporting text, image, and audio inputs with foundational reasoning abilities.",
        "release_date": "2024-02-14",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 32760,
            "max_token_output": 8192,
            "training_cutoff": "2023-02",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 1.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "google/gemini-pro-1.0",
            "google/gemini-pro",
            "google/gemini-1.0-pro"
        ],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-1.0-pro-002",
        "full_key": "google/gemini-1.0-pro-002",
        "slug": "google_gemini-1.0-pro-002"
    },
    "google/gemini-1.0-pro": {
        "company": "Google",
        "label": "Gemini 1.0 Pro 002",
        "description": "Gemini 1.0 Pro is an earlier generation multimodal model supporting text, image, and audio inputs with foundational reasoning abilities.",
        "release_date": "2024-02-14",
        "open_source": false,
        "documentation_url": "https://ai.google.dev/gemini-api/docs/models",
        "properties": {
            "context_window": 32760,
            "max_token_output": 8192,
            "training_cutoff": "2023-02",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 1.5,
            "cache": {
                "read_discount": 0.25,
                "write_markup": 1.0
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "google",
        "provider_endpoint": "gemini-1.0-pro-002",
        "full_key": "google/gemini-1.0-pro",
        "slug": "google_gemini-1.0-pro"
    },
    "openai/gpt-4-turbo-preview": {
        "company": "OpenAI",
        "label": "GPT 4 Turbo Preview",
        "description": "GPT-4 Turbo Preview is a research preview of an older GPT model.",
        "release_date": "2024-01-25",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4-turbo-preview",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 10.0,
            "output": 30.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4-turbo-preview",
        "full_key": "openai/gpt-4-turbo-preview",
        "slug": "openai_gpt-4-turbo-preview"
    },
    "openai/gpt-4-0125-preview": {
        "company": "OpenAI",
        "label": "GPT 4 Preview",
        "description": "GPT-4 Turbo preview model intended to reduce cases of laziness where the model doesn't complete a task.",
        "release_date": "2024-01-25",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4",
        "properties": {
            "context_window": 128000,
            "max_token_output": 4096,
            "training_cutoff": "2023-12",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 10.0,
            "output": 30.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4-0125-preview",
        "full_key": "openai/gpt-4-0125-preview",
        "slug": "openai_gpt-4-0125-preview"
    },
    "together/mistralai/Mixtral-8x7B-v0.1": {
        "company": "Mistral",
        "label": "Mixtral (8x7B)",
        "description": "Mixtral model, combining 8x7B modules fine-tuned for complex tasks.",
        "release_date": "2023-12-15",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.6,
            "output": 0.6
        },
        "alternative_keys": [
            "together/Mixtral-8x7B-v0.1"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mixtral-8x7B-v0.1",
        "full_key": "together/mistralai/Mixtral-8x7B-v0.1",
        "slug": "together_mistralai_Mixtral-8x7B-v0.1"
    },
    "together/mistralai/Mixtral-8x7B-Instruct-v0.1": {
        "company": "Mistral",
        "label": "Mixtral Instruct (8x7B)",
        "description": "Mixtral model, combining 8x7B Instruct modules fine-tuned for complex tasks.",
        "release_date": "2023-12-15",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.6,
            "output": 0.6
        },
        "alternative_keys": [
            "together/Mixtral-8x7B-Instruct-v0.1"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "full_key": "together/mistralai/Mixtral-8x7B-Instruct-v0.1",
        "slug": "together_mistralai_Mixtral-8x7B-Instruct-v0.1"
    },
    "together/mistralai/Mistral-7B-Instruct-v0.2": {
        "company": "Mistral",
        "label": "Mistral Instruct (7B) v0.2",
        "description": "Improved second version of Mistral 7B Instruct model.",
        "release_date": "2023-12-15",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [
            "together/Mistral-7B-Instruct-v0.2"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mistral-7B-Instruct-v0.2",
        "full_key": "together/mistralai/Mistral-7B-Instruct-v0.2",
        "slug": "together_mistralai_Mistral-7B-Instruct-v0.2"
    },
    "together/Mixtral-8x7B-v0.1": {
        "company": "Mistral",
        "label": "Mixtral (8x7B)",
        "description": "Mixtral model, combining 8x7B modules fine-tuned for complex tasks.",
        "release_date": "2023-12-15",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.6,
            "output": 0.6
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mixtral-8x7B-v0.1",
        "full_key": "together/Mixtral-8x7B-v0.1",
        "slug": "together_Mixtral-8x7B-v0.1"
    },
    "together/Mixtral-8x7B-Instruct-v0.1": {
        "company": "Mistral",
        "label": "Mixtral Instruct (8x7B)",
        "description": "Mixtral model, combining 8x7B Instruct modules fine-tuned for complex tasks.",
        "release_date": "2023-12-15",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.6,
            "output": 0.6
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "full_key": "together/Mixtral-8x7B-Instruct-v0.1",
        "slug": "together_Mixtral-8x7B-Instruct-v0.1"
    },
    "together/Mistral-7B-Instruct-v0.2": {
        "company": "Mistral",
        "label": "Mistral Instruct (7B) v0.2",
        "description": "Improved second version of Mistral 7B Instruct model.",
        "release_date": "2023-12-15",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mistral-7B-Instruct-v0.2",
        "full_key": "together/Mistral-7B-Instruct-v0.2",
        "slug": "together_Mistral-7B-Instruct-v0.2"
    },
    "together/mistralai/Mistral-7B-v0.1": {
        "company": "Mistral",
        "label": "Mistral (7B)",
        "description": "First version of Mistral 7B model.",
        "release_date": "2023-09-27",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-06",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [
            "together/Mistral-7B-v0.1"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mistral-7B-v0.1",
        "full_key": "together/mistralai/Mistral-7B-v0.1",
        "slug": "together_mistralai_Mistral-7B-v0.1"
    },
    "together/mistralai/Mistral-7B-Instruct-v0.1": {
        "company": "Mistral",
        "label": "Mistral Instruct (7B) v0.1",
        "description": "First version of Mistral 7B Instruct model.",
        "release_date": "2023-09-27",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-06",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [
            "together/Mistral-7B-Instruct-v0.1"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mistral-7B-Instruct-v0.1",
        "full_key": "together/mistralai/Mistral-7B-Instruct-v0.1",
        "slug": "together_mistralai_Mistral-7B-Instruct-v0.1"
    },
    "together/Mistral-7B-v0.1": {
        "company": "Mistral",
        "label": "Mistral (7B)",
        "description": "First version of Mistral 7B model.",
        "release_date": "2023-09-27",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 8192,
            "max_token_output": 4096,
            "training_cutoff": "2023-06",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mistral-7B-v0.1",
        "full_key": "together/Mistral-7B-v0.1",
        "slug": "together_Mistral-7B-v0.1"
    },
    "together/Mistral-7B-Instruct-v0.1": {
        "company": "Mistral",
        "label": "Mistral Instruct (7B) v0.1",
        "description": "First version of Mistral 7B Instruct model.",
        "release_date": "2023-09-27",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 32768,
            "max_token_output": 4096,
            "training_cutoff": "2023-06",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.18,
            "output": 0.18
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "mistralai/Mistral-7B-Instruct-v0.1",
        "full_key": "together/Mistral-7B-Instruct-v0.1",
        "slug": "together_Mistral-7B-Instruct-v0.1"
    },
    "together/togethercomputer/llama-2-7b-chat": {
        "company": "Meta",
        "label": "Llama 2 Chat (7B)",
        "description": "Llama 2 Reference Model, 7B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [
            "together/llama-2-7b-chat"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/llama-2-7b-chat",
        "full_key": "together/togethercomputer/llama-2-7b-chat",
        "slug": "together_togethercomputer_llama-2-7b-chat"
    },
    "together/togethercomputer/llama-2-7b": {
        "company": "Meta",
        "label": "Llama 2 (7B)",
        "description": "Llama 2 Reference Model, 7B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [
            "together/llama-2-7b"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/llama-2-7b",
        "full_key": "together/togethercomputer/llama-2-7b",
        "slug": "together_togethercomputer_llama-2-7b"
    },
    "together/togethercomputer/llama-2-70b-chat": {
        "company": "Meta",
        "label": "Llama 2 Chat (70B)",
        "description": "Llama 2 Reference Model, 70B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9
        },
        "alternative_keys": [
            "together/llama-2-70b-chat"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/llama-2-70b-chat",
        "full_key": "together/togethercomputer/llama-2-70b-chat",
        "slug": "together_togethercomputer_llama-2-70b-chat"
    },
    "together/togethercomputer/llama-2-13b-chat": {
        "company": "Meta",
        "label": "Llama 2 Chat (13B)",
        "description": "Llama 2 Reference Model, 13B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.3
        },
        "alternative_keys": [
            "together/llama-2-13b-chat"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/llama-2-13b-chat",
        "full_key": "together/togethercomputer/llama-2-13b-chat",
        "slug": "together_togethercomputer_llama-2-13b-chat"
    },
    "together/togethercomputer/llama-2-13b": {
        "company": "Meta",
        "label": "Llama 2 (13B)",
        "description": "Llama 2 Reference Model, 13B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [
            "together/llama-2-13b"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/llama-2-13b",
        "full_key": "together/togethercomputer/llama-2-13b",
        "slug": "together_togethercomputer_llama-2-13b"
    },
    "together/meta-llama/Llama-2-7b-hf": {
        "company": "Meta",
        "label": "Llama 2 (7B)",
        "description": "Llama 2 Reference Model, 7B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-2-7b-hf",
        "full_key": "together/meta-llama/Llama-2-7b-hf",
        "slug": "together_meta-llama_Llama-2-7b-hf"
    },
    "together/meta-llama/Llama-2-7b-chat-hf": {
        "company": "Meta",
        "label": "Llama 2 Chat (7B)",
        "description": "Llama 2 Reference Model, 7B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-2-7b-chat-hf",
        "full_key": "together/meta-llama/Llama-2-7b-chat-hf",
        "slug": "together_meta-llama_Llama-2-7b-chat-hf"
    },
    "together/meta-llama/Llama-2-70b-hf": {
        "company": "Meta",
        "label": "Llama 2 (70B)",
        "description": "Llama 2 Reference Model, 70B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9
        },
        "alternative_keys": [
            "together/llama-2-70b"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-2-70b-hf",
        "full_key": "together/meta-llama/Llama-2-70b-hf",
        "slug": "together_meta-llama_Llama-2-70b-hf"
    },
    "together/meta-llama/Llama-2-70b-chat-hf": {
        "company": "Meta",
        "label": "Llama 2 Chat (70B)",
        "description": "Llama 2 Reference Model, 70B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-2-70b-chat-hf",
        "full_key": "together/meta-llama/Llama-2-70b-chat-hf",
        "slug": "together_meta-llama_Llama-2-70b-chat-hf"
    },
    "together/meta-llama/Llama-2-13b-hf": {
        "company": "Meta",
        "label": "Llama 2 (13B)",
        "description": "Llama 2 Reference Model, 13B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.3
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-2-13b-hf",
        "full_key": "together/meta-llama/Llama-2-13b-hf",
        "slug": "together_meta-llama_Llama-2-13b-hf"
    },
    "together/meta-llama/Llama-2-13b-chat-hf": {
        "company": "Meta",
        "label": "Llama 2 Chat (13B)",
        "description": "Llama 2 Reference Model, 13B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.3
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-2-13b-chat-hf",
        "full_key": "together/meta-llama/Llama-2-13b-chat-hf",
        "slug": "together_meta-llama_Llama-2-13b-chat-hf"
    },
    "together/llama-2-7b-chat": {
        "company": "Meta",
        "label": "Llama 2 Chat (7B)",
        "description": "Llama 2 Reference Model, 7B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/llama-2-7b-chat",
        "full_key": "together/llama-2-7b-chat",
        "slug": "together_llama-2-7b-chat"
    },
    "together/llama-2-7b": {
        "company": "Meta",
        "label": "Llama 2 (7B)",
        "description": "Llama 2 Reference Model, 7B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/llama-2-7b",
        "full_key": "together/llama-2-7b",
        "slug": "together_llama-2-7b"
    },
    "together/llama-2-70b-chat": {
        "company": "Meta",
        "label": "Llama 2 Chat (70B)",
        "description": "Llama 2 Reference Model, 70B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/llama-2-70b-chat",
        "full_key": "together/llama-2-70b-chat",
        "slug": "together_llama-2-70b-chat"
    },
    "together/llama-2-70b": {
        "company": "Meta",
        "label": "Llama 2 (70B)",
        "description": "Llama 2 Reference Model, 70B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.9,
            "output": 0.9
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "meta-llama/Llama-2-70b-hf",
        "full_key": "together/llama-2-70b",
        "slug": "together_llama-2-70b"
    },
    "together/llama-2-13b-chat": {
        "company": "Meta",
        "label": "Llama 2 Chat (13B)",
        "description": "Llama 2 Reference Model, 13B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.3,
            "output": 0.3
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/llama-2-13b-chat",
        "full_key": "together/llama-2-13b-chat",
        "slug": "together_llama-2-13b-chat"
    },
    "together/llama-2-13b": {
        "company": "Meta",
        "label": "Llama 2 (13B)",
        "description": "Llama 2 Reference Model, 13B parameters with FP16 quantization.",
        "release_date": "2023-07-18",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2022-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/llama-2-13b",
        "full_key": "together/llama-2-13b",
        "slug": "together_llama-2-13b"
    },
    "together/togethercomputer/falcon-7b-instruct": {
        "company": "Technology Innovation Institute",
        "label": "Falcon Instruct (7B)",
        "description": "Falcon 7B Instruct model.",
        "release_date": "2023-06-20",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [
            "together/falcon-7b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/falcon-7b-instruct",
        "full_key": "together/togethercomputer/falcon-7b-instruct",
        "slug": "together_togethercomputer_falcon-7b-instruct"
    },
    "together/togethercomputer/falcon-7b": {
        "company": "Technology Innovation Institute",
        "label": "Falcon (7B)",
        "description": "Falcon 7B model.",
        "release_date": "2023-06-20",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [
            "together/falcon-7b"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/falcon-7b",
        "full_key": "together/togethercomputer/falcon-7b",
        "slug": "together_togethercomputer_falcon-7b"
    },
    "together/falcon-7b-instruct": {
        "company": "Technology Innovation Institute",
        "label": "Falcon Instruct (7B)",
        "description": "Falcon 7B Instruct model.",
        "release_date": "2023-06-20",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/falcon-7b-instruct",
        "full_key": "together/falcon-7b-instruct",
        "slug": "together_falcon-7b-instruct"
    },
    "together/falcon-7b": {
        "company": "Technology Innovation Institute",
        "label": "Falcon (7B)",
        "description": "Falcon 7B model.",
        "release_date": "2023-06-20",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/falcon-7b",
        "full_key": "together/falcon-7b",
        "slug": "together_falcon-7b"
    },
    "openai/gpt-4": {
        "company": "OpenAI",
        "label": "GPT 4",
        "description": "GPT-4 is an older high-intelligence GPT model for text-only conversations.",
        "release_date": "2023-06-13",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-4",
        "properties": {
            "context_window": 8192,
            "max_token_output": 8192,
            "training_cutoff": "2021-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 30.0,
            "output": 60.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4",
        "full_key": "openai/gpt-4",
        "slug": "openai_gpt-4"
    },
    "together/togethercomputer/falcon-40b-instruct": {
        "company": "Technology Innovation Institute",
        "label": "Falcon Instruct (40B)",
        "description": "Falcon 40B Instruct model.",
        "release_date": "2023-05-25",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 0.8
        },
        "alternative_keys": [
            "together/falcon-40b-instruct"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/falcon-40b-instruct",
        "full_key": "together/togethercomputer/falcon-40b-instruct",
        "slug": "together_togethercomputer_falcon-40b-instruct"
    },
    "together/togethercomputer/falcon-40b": {
        "company": "Technology Innovation Institute",
        "label": "Falcon (40B)",
        "description": "Falcon 40B model.",
        "release_date": "2023-05-25",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 0.8
        },
        "alternative_keys": [
            "together/falcon-40b"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/falcon-40b",
        "full_key": "together/togethercomputer/falcon-40b",
        "slug": "together_togethercomputer_falcon-40b"
    },
    "together/falcon-40b-instruct": {
        "company": "Technology Innovation Institute",
        "label": "Falcon Instruct (40B)",
        "description": "Falcon 40B Instruct model.",
        "release_date": "2023-05-25",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 0.8
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/falcon-40b-instruct",
        "full_key": "together/falcon-40b-instruct",
        "slug": "together_falcon-40b-instruct"
    },
    "together/falcon-40b": {
        "company": "Technology Innovation Institute",
        "label": "Falcon (40B)",
        "description": "Falcon 40B model.",
        "release_date": "2023-05-25",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 0.8
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/falcon-40b",
        "full_key": "together/falcon-40b",
        "slug": "together_falcon-40b"
    },
    "openai/gpt-4-0314": {
        "company": "OpenAI",
        "label": "GPT 4 (2023-03-14)",
        "description": "Snapshot of gpt-4 from March 14th 2023. (Legacy)",
        "release_date": "2023-03-14",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4",
        "properties": {
            "context_window": 8192,
            "max_token_output": 8192,
            "training_cutoff": "2021-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 30.0,
            "output": 60.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4-0314",
        "full_key": "openai/gpt-4-0314",
        "slug": "openai_gpt-4-0314"
    },
    "together/togethercomputer/alpaca-7b": {
        "company": "Stanford",
        "label": "Alpaca (7B)",
        "description": "Alpaca 7B Instruct model.",
        "release_date": "2023-03-13",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [
            "together/alpaca-7b"
        ],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/alpaca-7b",
        "full_key": "together/togethercomputer/alpaca-7b",
        "slug": "together_togethercomputer_alpaca-7b"
    },
    "together/alpaca-7b": {
        "company": "Stanford",
        "label": "Alpaca (7B)",
        "description": "Alpaca 7B Instruct model.",
        "release_date": "2023-03-13",
        "open_source": true,
        "documentation_url": "https://docs.together.ai/docs/serverless-models",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": true,
            "supports_files": false,
            "supports_tools": false,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.2,
            "output": 0.2
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "together",
        "provider_endpoint": "togethercomputer/alpaca-7b",
        "full_key": "together/alpaca-7b",
        "slug": "together_alpaca-7b"
    },
    "openai/gpt-3.5-turbo-0125": {
        "company": "OpenAI",
        "label": "GPT 3.5 (2023-01-25)",
        "description": "The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats.",
        "release_date": "2023-01-25",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models#gpt-3-5-turbo",
        "properties": {
            "context_window": 16385,
            "max_token_output": 4096,
            "training_cutoff": "2021-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 1.5,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-3.5-turbo-0125",
        "full_key": "openai/gpt-3.5-turbo-0125",
        "slug": "openai_gpt-3.5-turbo-0125"
    },
    "openai/gpt-3.5-turbo": {
        "company": "OpenAI",
        "label": "GPT 3.5",
        "description": "GPT-3.5 Turbo is a legacy text-only model for natural language and code conversations.",
        "release_date": "2023-01-25",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-3.5-turbo",
        "properties": {
            "context_window": 16385,
            "max_token_output": 4096,
            "training_cutoff": "2021-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 1.5,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "openai/gpt-3.5"
        ],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-3.5-turbo",
        "full_key": "openai/gpt-3.5-turbo",
        "slug": "openai_gpt-3.5-turbo"
    },
    "openai/gpt-3.5": {
        "company": "OpenAI",
        "label": "GPT 3.5",
        "description": "GPT-3.5 Turbo is a legacy text-only model for natural language and code conversations.",
        "release_date": "2023-01-25",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-3.5-turbo",
        "properties": {
            "context_window": 16385,
            "max_token_output": 4096,
            "training_cutoff": "2021-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.5,
            "output": 1.5,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-3.5-turbo",
        "full_key": "openai/gpt-3.5",
        "slug": "openai_gpt-3.5"
    },
    "openai/gpt-3.5-turbo-instruct": {
        "company": "OpenAI",
        "label": "GPT 3.5 Turbo Instruct",
        "description": "GPT-3.5-turbo-instruct is an older model compatible only with the legacy Completions endpoint for text-based workflows.",
        "release_date": "2022-11-06",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models/gpt-3.5-turbo-instruct",
        "properties": {
            "context_window": 4096,
            "max_token_output": 4096,
            "training_cutoff": "2021-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.5,
            "output": 2.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-3.5-turbo-instruct",
        "full_key": "openai/gpt-3.5-turbo-instruct",
        "slug": "openai_gpt-3.5-turbo-instruct"
    },
    "openai/gpt-3.5-turbo-1106": {
        "company": "OpenAI",
        "label": "GPT 3.5 Turbo (2022-11-06)",
        "description": "GPT-3.5 Turbo model with improved instruction following and JSON mode.",
        "release_date": "2022-11-06",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models#gpt-3-5-turbo",
        "properties": {
            "context_window": 16385,
            "max_token_output": 4096,
            "training_cutoff": "2021-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.0,
            "output": 2.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-3.5-turbo-1106",
        "full_key": "openai/gpt-3.5-turbo-1106",
        "slug": "openai_gpt-3.5-turbo-1106"
    },
    "vals/dumbmar-5o-ultra-thinking": {
        "company": "Vals AI",
        "label": "Dummy Model",
        "description": "Vals Dummy Model for testing",
        "open_source": false,
        "documentation_url": "",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": ""
        },
        "class_properties": {
            "supports_images": false,
            "supports_batch_requests": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6,
            "cache": {
                "read": 0.075,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "vals",
        "provider_endpoint": "dumbmar-5o-ultra-thinking",
        "full_key": "vals/dumbmar-5o-ultra-thinking",
        "slug": "vals_dumbmar-5o-ultra-thinking"
    },
    "vals/dumbmar-5o-evaluator": {
        "company": "Vals AI",
        "label": "Dummy Evaluator Model",
        "description": "Vals Dummy Model for evaluating",
        "open_source": false,
        "documentation_url": "",
        "properties": {
            "context_window": 128000,
            "max_token_output": 16384,
            "training_cutoff": ""
        },
        "class_properties": {
            "supports_images": false,
            "supports_batch_requests": true,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": true,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.15,
            "output": 0.6,
            "cache": {
                "read": 0.075,
                "write_markup": 1.0
            }
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "vals",
        "provider_endpoint": "dumbmar-5o-evaluator",
        "full_key": "vals/dumbmar-5o-evaluator",
        "slug": "vals_dumbmar-5o-evaluator"
    },
    "perplexity/sonar-reasoning-pro": {
        "company": "Perplexity",
        "label": "Sonar Reasoning Pro",
        "description": "Advanced reasoning model combining multi-step analysis with rich web retrieval.",
        "open_source": false,
        "documentation_url": "https://docs.perplexity.ai/models/models/sonar-reasoning-pro",
        "properties": {
            "context_window": 128000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "perplexity",
        "provider_endpoint": "sonar-reasoning-pro",
        "full_key": "perplexity/sonar-reasoning-pro",
        "slug": "perplexity_sonar-reasoning-pro"
    },
    "perplexity/sonar-reasoning": {
        "company": "Perplexity",
        "label": "Sonar Reasoning",
        "description": "Reasoning-focused search model that exposes intermediate thinking for step-by-step answers.",
        "open_source": false,
        "documentation_url": "https://docs.perplexity.ai/models/models/sonar-reasoning",
        "properties": {
            "context_window": 128000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.0,
            "output": 5.0
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "perplexity",
        "provider_endpoint": "sonar-reasoning",
        "full_key": "perplexity/sonar-reasoning",
        "slug": "perplexity_sonar-reasoning"
    },
    "perplexity/sonar-pro": {
        "company": "Perplexity",
        "label": "Sonar Pro",
        "description": "Premium search model for deeper research and analytical tasks with higher context window.",
        "open_source": false,
        "documentation_url": "https://docs.perplexity.ai/models/models/sonar-pro",
        "properties": {
            "context_window": 200000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 3.0,
            "output": 15.0
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "perplexity",
        "provider_endpoint": "sonar-pro",
        "full_key": "perplexity/sonar-pro",
        "slug": "perplexity_sonar-pro"
    },
    "perplexity/sonar-deep-research": {
        "company": "Perplexity",
        "label": "Sonar Deep Research",
        "description": "Exhaustive research agent that performs multi-engine search, reasoning, and source synthesis.",
        "open_source": false,
        "documentation_url": "https://docs.perplexity.ai/models/models/sonar-deep-research",
        "properties": {
            "context_window": 128000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": true
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 2.0,
            "output": 8.0
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "perplexity",
        "provider_endpoint": "sonar-deep-research",
        "full_key": "perplexity/sonar-deep-research",
        "slug": "perplexity_sonar-deep-research"
    },
    "perplexity/sonar": {
        "company": "Perplexity",
        "label": "Sonar",
        "description": "Lightweight web search model optimized for fast factual answers with citations.",
        "open_source": false,
        "documentation_url": "https://docs.perplexity.ai/models/models/sonar",
        "properties": {
            "context_window": 128000,
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": false,
            "supports_temperature": true,
            "supports_tools": false,
            "deprecated": false,
            "available_for_everyone": true,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 1.0,
            "output": 1.0
        },
        "alternative_keys": [],
        "default_parameters": {},
        "provider_name": "perplexity",
        "provider_endpoint": "sonar",
        "full_key": "perplexity/sonar",
        "slug": "perplexity_sonar"
    },
    "openai/gpt-4-0613": {
        "company": "OpenAI",
        "label": "GPT 4 (2023-06-13)",
        "description": "Snapshot of GPT-4 from June 13th 2023 with improved function calling support.",
        "open_source": false,
        "documentation_url": "https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4",
        "properties": {
            "context_window": 8192,
            "max_token_output": 8192,
            "training_cutoff": "2021-09",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": false,
            "supports_batch_requests": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 30.0,
            "output": 60.0,
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0,
            "reasoning_effort": "high"
        },
        "provider_name": "openai",
        "provider_endpoint": "gpt-4-0613",
        "full_key": "openai/gpt-4-0613",
        "slug": "openai_gpt-4-0613"
    },
    "anthropic/claude-instant-1.2": {
        "company": "Anthropic",
        "label": "Claude Instant 1.2",
        "description": "Claude Instant 1.2 was Anthropic's rapid-response, cost-optimized model for text-based queries, chat, and basic NLP workflows. It was tuned for high query volume and conversational tasks.",
        "open_source": false,
        "documentation_url": "",
        "properties": {
            "context_window": 100000,
            "max_token_output": 4096,
            "training_cutoff": "Early 2023",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 2.4,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "anthropic/claude-instant"
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-instant-1.2",
        "full_key": "anthropic/claude-instant-1.2",
        "slug": "anthropic_claude-instant-1.2"
    },
    "anthropic/claude-instant": {
        "company": "Anthropic",
        "label": "Claude Instant 1.2",
        "description": "Claude Instant 1.2 was Anthropic's rapid-response, cost-optimized model for text-based queries, chat, and basic NLP workflows. It was tuned for high query volume and conversational tasks.",
        "open_source": false,
        "documentation_url": "",
        "properties": {
            "context_window": 100000,
            "max_token_output": 4096,
            "training_cutoff": "Early 2023",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.8,
            "output": 2.4,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-instant-1.2",
        "full_key": "anthropic/claude-instant",
        "slug": "anthropic_claude-instant"
    },
    "anthropic/claude-2.1": {
        "company": "Anthropic",
        "label": "Claude 2.1",
        "description": "Claude 2.1 provided safer, more capable text generation and QA compared to previous versions, offering a 100K token context window and robust instruction following for business and developer use cases.",
        "open_source": false,
        "documentation_url": "",
        "properties": {
            "context_window": 200000,
            "max_token_output": 4096,
            "training_cutoff": "Early 2023",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 8.0,
            "output": 24.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [
            "anthropic/claude-2"
        ],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-2.1",
        "full_key": "anthropic/claude-2.1",
        "slug": "anthropic_claude-2.1"
    },
    "anthropic/claude-2.0": {
        "company": "Anthropic",
        "label": "Claude 2",
        "description": "Claude 2.0 was a general purpose conversational model for text-only input and output, known for helpfulness, reliability, and improved safety compared to Claude 1.x. It supported longer conversations and basic analysis.",
        "open_source": false,
        "documentation_url": "",
        "properties": {
            "context_window": 100000,
            "max_token_output": 4096,
            "training_cutoff": "Early 2023",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 8.0,
            "output": 24.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-2.0",
        "full_key": "anthropic/claude-2.0",
        "slug": "anthropic_claude-2.0"
    },
    "anthropic/claude-2": {
        "company": "Anthropic",
        "label": "Claude 2.1",
        "description": "Claude 2.1 provided safer, more capable text generation and QA compared to previous versions, offering a 100K token context window and robust instruction following for business and developer use cases.",
        "open_source": false,
        "documentation_url": "",
        "properties": {
            "context_window": 200000,
            "max_token_output": 4096,
            "training_cutoff": "Early 2023",
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 8.0,
            "output": 24.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-2.1",
        "full_key": "anthropic/claude-2",
        "slug": "anthropic_claude-2"
    },
    "anthropic/claude-1.3": {
        "company": "Anthropic",
        "label": "Claude 1.3",
        "description": "Claude 1.3 was one of Anthropic's earliest conversational models.",
        "open_source": false,
        "documentation_url": "",
        "properties": {
            "max_token_output": null,
            "training_cutoff": null,
            "reasoning_model": false
        },
        "class_properties": {
            "supports_images": false,
            "supports_files": true,
            "supports_temperature": true,
            "supports_tools": true,
            "deprecated": true,
            "available_for_everyone": false,
            "available_as_evaluator": false,
            "ignored_for_cost": false
        },
        "provider_properties": {},
        "costs_per_million_token": {
            "input": 0.0,
            "output": 0.0,
            "cache": {
                "read_discount": 0.1,
                "write_markup": 1.25
            },
            "batch": {
                "input_discount": 0.5,
                "output_discount": 0.5
            }
        },
        "alternative_keys": [],
        "default_parameters": {
            "temperature": 1.0
        },
        "provider_name": "anthropic",
        "provider_endpoint": "claude-1.3",
        "full_key": "anthropic/claude-1.3",
        "slug": "anthropic_claude-1.3"
    }
}